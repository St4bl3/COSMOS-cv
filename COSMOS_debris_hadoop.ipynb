{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c63eaf27",
      "metadata": {},
      "source": [
        "## Space Debris Detection using PySpark, Faster R-CNN (Reading from HDFS & Skipping Trained Epochs)\n",
        "\n",
        "This notebook trains a pre-trained Faster R-CNN model to detect space debris in images.\n",
        "**Key Features:**\n",
        "* **PySpark for Preprocessing:** Annotation data (CSVs) is loaded and preprocessed using PySpark from HDFS.\n",
        "* **PyTorch for Training:** A Faster R-CNN model is trained using PyTorch, leveraging GPU if available.\n",
        "* **HDFS Data Source:** Images are read directly from HDFS using the `hdfs` library within the PyTorch Dataset.\n",
        "* **Checkpointing:** Checks for existing model checkpoints locally and skips training for epochs that have already been saved.\n",
        "\n",
        "**Prerequisites:**\n",
        "* `pyspark` installed (`pip install pyspark`).\n",
        "* `hdfs` library installed (`pip install hdfs`).\n",
        "* WebHDFS enabled in your Hadoop `hdfs-site.xml` configuration and HDFS restarted.\n",
        "* Know your WebHDFS URL (e.g., `http://localhost:9870`) and HDFS username.\n",
        "* **(Optional)** Previously trained model checkpoints saved locally in the directory specified (`model_save_dir`).\n",
        "\n",
        "**Project Steps:**\n",
        "1.  **Setup:** Import libraries, check environment, import HDFS client library.\n",
        "2.  **PySpark Session & Configuration:** Initialize SparkSession and configure HDFS paths, WebHDFS URL, HDFS user, local model directory, training parameters, and device.\n",
        "3.  **PySpark Data Loading & Preprocessing:** \n",
        "    * Read annotation CSVs (train & validation) from HDFS into Spark DataFrames.\n",
        "    * Define and apply a User Defined Function (UDF) to parse bounding box strings.\n",
        "4.  **Data Preparation for PyTorch:** Convert processed Spark DataFrames into a format suitable for the PyTorch Dataset (e.g., list of dictionaries or Pandas DataFrame).\n",
        "5.  **PyTorch Custom Dataset:** Define a PyTorch Dataset to load images from HDFS (using paths from Spark) and apply transformations.\n",
        "6.  **Transforms:** Define image transformations for training and validation.\n",
        "7.  **Model Definition:** Load and adapt the Faster R-CNN model architecture.\n",
        "8.  **Dataloaders & HDFS Client:** Create PyTorch DataLoaders and initialize the HDFS client for image loading.\n",
        "9.  **Training:** Train the model on GPU, skipping epochs if a checkpoint file already exists locally, saving new checkpoints locally.\n",
        "10. **Visualization:** Plot the training loss.\n",
        "11. **Evaluation:** Load the latest model and evaluate it on the validation set.\n",
        "12. **Inference:** Demonstrate inference on a single image from HDFS."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e27f7040",
      "metadata": {},
      "source": [
        "### Cell 1: Imports and Environment Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f78ac2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Imports\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as T # Using v1 transforms\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import os\n",
        "import sys # Added sys module\n",
        "import ast\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "import traceback\n",
        "import io # Needed for reading from HDFS stream\n",
        "\n",
        "# --- PySpark Imports ---\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf, col, split, size, expr, when\n",
        "from pyspark.sql.types import ArrayType, StructType, StructField, FloatType, StringType, IntegerType\n",
        "\n",
        "# --- HDFS Import (WebHDFS Client for PyTorch Dataset) ---\n",
        "from hdfs import InsecureClient # Use InsecureClient if no Kerberos\n",
        "import requests # For HDFS client connection error handling\n",
        "\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"Torchvision Version: {torchvision.__version__}\")\n",
        "print(f\"PySpark Version: {pyspark.__version__}\")\n",
        "\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57d9f7d2",
      "metadata": {},
      "source": [
        "### Cell 2: PySpark Session Initialization & Configuration\n",
        "Configure HDFS paths, WebHDFS connection details, local model directory, and training hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49614d4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: PySpark Session & Configuration\n",
        "\n",
        "# --- Set PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON to current environment's Python ---\n",
        "# This helps ensure Spark workers use the same Python environment as the driver (notebook kernel).\n",
        "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
        "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
        "print(f\"PYSPARK_PYTHON set to: {sys.executable}\")\n",
        "print(f\"PYSPARK_DRIVER_PYTHON set to: {sys.executable}\")\n",
        "\n",
        "# --- Initialize Spark Session ---\n",
        "try:\n",
        "    if 'spark' in globals() and spark is not None:\n",
        "        print(\"Stopping existing Spark session...\")\n",
        "        spark.stop()\n",
        "        print(\"Spark session stopped.\")\n",
        "except NameError:\n",
        "    print(\"No existing Spark session named 'spark' to stop.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error stopping existing Spark session: {e}\")\n",
        "\n",
        "print(\"Initializing new Spark session...\")\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"SpaceDebrisPreprocessing\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
        "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
        "    .config(\"spark.executor.memory\", \"2g\") \\\n",
        "    .config(\"spark.driver.memory\", \"2g\") \\\n",
        "    .config(\"spark.python.worker.timeout\", \"600s\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "print(f\"Spark Session Initialized. Spark version: {spark.version}\")\n",
        "\n",
        "# --- HDFS Base Path (for PySpark and PyTorch) ---\n",
        "base_hdfs_path = \"/user/dhanu/debris-detection\" \n",
        "\n",
        "# --- WebHDFS Connection Details (for PyTorch HDFS client) ---\n",
        "webhdfs_url = \"http://localhost:9870\" \n",
        "hdfs_user = \"dhanu\" \n",
        "\n",
        "train_dir_hdfs = f\"{base_hdfs_path}/train\"\n",
        "val_dir_hdfs = f\"{base_hdfs_path}/val\"\n",
        "test_dir_hdfs = f\"{base_hdfs_path}/test\"\n",
        "\n",
        "train_csv_hdfs_path = f\"hdfs://localhost:9000{base_hdfs_path}/train.csv\" \n",
        "val_csv_hdfs_path = f\"hdfs://localhost:9000{base_hdfs_path}/val.csv\"     \n",
        "\n",
        "model_save_dir = r\"./debris_models_pyspark\" \n",
        "os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "NUM_CLASSES = 2 \n",
        "NUM_EPOCHS = 15\n",
        "BATCH_SIZE = 2\n",
        "LEARNING_RATE = 0.0005\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 0.0005\n",
        "PYTORCH_NUM_WORKERS = 0 \n",
        "GRAD_CLIP_NORM = 1.0\n",
        "\n",
        "print(f\"--- Configuration ---\")\n",
        "print(f\"Using PyTorch device: {DEVICE}\")\n",
        "print(f\"WebHDFS URL (for PyTorch image loading): {webhdfs_url}\")\n",
        "print(f\"HDFS User (for WebHDFS): {hdfs_user}\")\n",
        "print(f\"Base HDFS path: {base_hdfs_path}\")\n",
        "print(f\"Train CSV HDFS path (for Spark): {train_csv_hdfs_path}\")\n",
        "print(f\"Val CSV HDFS path (for Spark): {val_csv_hdfs_path}\")\n",
        "print(f\"Model Save Path (Local): {model_save_dir}\")\n",
        "print(f\"Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"---------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc2bc324",
      "metadata": {},
      "source": [
        "### Cell 3: PySpark Data Loading and Preprocessing\n",
        "Load annotation CSVs from HDFS, parse bounding boxes, and prepare data for PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5f6f475",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: PySpark Data Loading and Preprocessing\n",
        "\n",
        "# Define schema for a single bounding box (xmin, ymin, xmax, ymax for model)\n",
        "bbox_struct = StructType([\n",
        "    StructField(\"xmin\", FloatType(), True),\n",
        "    StructField(\"ymin\", FloatType(), True),\n",
        "    StructField(\"xmax\", FloatType(), True),\n",
        "    StructField(\"ymax\", FloatType(), True)\n",
        "])\n",
        "\n",
        "# Define schema for a list of bounding boxes\n",
        "bboxes_list_schema = ArrayType(bbox_struct)\n",
        "\n",
        "# UDF to parse bounding box strings\n",
        "@udf(returnType=bboxes_list_schema)\n",
        "def parse_bboxes_udf(bbox_str):\n",
        "    if bbox_str is None or not str(bbox_str).strip():\n",
        "        return []\n",
        "    try:\n",
        "        s_bbox_str = str(bbox_str)\n",
        "        if not (s_bbox_str.startswith('[') and s_bbox_str.endswith(']')):\n",
        "            return []\n",
        "        raw_boxes_list = ast.literal_eval(s_bbox_str)\n",
        "        parsed_boxes = []\n",
        "        if isinstance(raw_boxes_list, list):\n",
        "            for box_coords in raw_boxes_list:\n",
        "                if isinstance(box_coords, (list, tuple)) and len(box_coords) == 4:\n",
        "                    try:\n",
        "                        # Original format in CSV: [xmin, xmax, ymin, ymax]\n",
        "                        xmin_csv, xmax_csv, ymin_csv, ymax_csv = map(float, box_coords)\n",
        "                        \n",
        "                        # Convert to model format [xmin, ymin, xmax, ymax]\n",
        "                        # Ensure valid box dimensions (xmax > xmin, ymax > ymin)\n",
        "                        if xmax_csv > xmin_csv and ymax_csv > ymin_csv:\n",
        "                            parsed_boxes.append({\n",
        "                                \"xmin\": float(xmin_csv), # Correct assignment\n",
        "                                \"ymin\": float(ymin_csv), # Correct assignment\n",
        "                                \"xmax\": float(xmax_csv), # Correct assignment\n",
        "                                \"ymax\": float(ymax_csv)  # Correct assignment\n",
        "                            })\n",
        "                    except ValueError:\n",
        "                        continue \n",
        "        return parsed_boxes\n",
        "    except (ValueError, SyntaxError, TypeError):\n",
        "        return []\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "def preprocess_annotations_spark(csv_path, image_dir_hdfs_base):\n",
        "    \"\"\"Loads CSV from HDFS, parses bboxes, and adds full image paths.\"\"\"\n",
        "    try:\n",
        "        df = spark.read.csv(csv_path, header=True, inferSchema=False, emptyValue='') \n",
        "        actual_cols = df.columns\n",
        "        image_id_col_name = None\n",
        "        bboxes_col_name = None\n",
        "\n",
        "        # Check for expected column names based on user input and common patterns\n",
        "        if 'ImageId' in actual_cols and 'bboxes0' in actual_cols:\n",
        "            image_id_col_name = 'ImageId'\n",
        "            bboxes_col_name = 'bboxes0'\n",
        "            print(f\"Using 'ImageId' and 'bboxes0' columns from {csv_path}\")\n",
        "        elif 'ImageID' in actual_cols and 'bboxes0' in actual_cols:\n",
        "            image_id_col_name = 'ImageID'\n",
        "            bboxes_col_name = 'bboxes0'\n",
        "            print(f\"Using 'ImageID' and 'bboxes0' columns from {csv_path}\")\n",
        "        elif 'ImageId' in actual_cols and 'bboxes' in actual_cols:\n",
        "            image_id_col_name = 'ImageId'\n",
        "            bboxes_col_name = 'bboxes'\n",
        "            print(f\"Using 'ImageId' and 'bboxes' columns from {csv_path}\")\n",
        "        elif 'ImageID' in actual_cols and 'bboxes' in actual_cols: \n",
        "            image_id_col_name = 'ImageID'\n",
        "            bboxes_col_name = 'bboxes'\n",
        "            print(f\"Using 'ImageID' and 'bboxes' columns from {csv_path}\")\n",
        "        elif 'ImageID' in actual_cols and 'Labels' in actual_cols:\n",
        "            image_id_col_name = 'ImageID'\n",
        "            bboxes_col_name = 'Labels'\n",
        "            print(f\"Using 'ImageID' and 'Labels' columns from {csv_path}\")\n",
        "        else:\n",
        "            if len(actual_cols) >= 2:\n",
        "                image_id_col_name = actual_cols[0]\n",
        "                bboxes_col_name = actual_cols[1]\n",
        "                print(f\"Warning: Using first two columns '{image_id_col_name}' and '{bboxes_col_name}' from {csv_path} as standard names were not found.\")\n",
        "            else:\n",
        "                raise ValueError(f\"CSV {csv_path} must have at least two columns for ImageId and bounding boxes. Found columns: {actual_cols}\")\n",
        "\n",
        "        df = df.withColumnRenamed(image_id_col_name, \"ImageId_orig\") \\\n",
        "                 .withColumnRenamed(bboxes_col_name, \"bbox_str_orig\")\n",
        "        \n",
        "        df = df.withColumn(\"ImageId\", col(\"ImageId_orig\").cast(StringType())) \\\n",
        "                 .withColumn(\"bbox_str\", col(\"bbox_str_orig\").cast(StringType()))\n",
        "        \n",
        "        df_processed = df.withColumn(\"bboxes_parsed\", parse_bboxes_udf(col(\"bbox_str\")))\n",
        "        df_processed = df_processed.withColumn(\"image_path_hdfs\", \n",
        "                                             expr(f\"concat('{image_dir_hdfs_base}/', ImageId, '.jpg')\"))\n",
        "        \n",
        "        df_final = df_processed.select(\"ImageId\", \"image_path_hdfs\", \"bboxes_parsed\") \\\n",
        "                               .withColumnRenamed(\"bboxes_parsed\", \"bboxes\")\n",
        "        \n",
        "        return df_final\n",
        "    except Exception as e:\n",
        "        print(f\"Error preprocessing CSV {csv_path} with Spark: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "print(\"Preprocessing training annotations with PySpark...\")\n",
        "train_df_spark = preprocess_annotations_spark(train_csv_hdfs_path, train_dir_hdfs)\n",
        "if train_df_spark:\n",
        "    train_df_spark.show(5, truncate=False)\n",
        "    print(f\"Training DataFrame schema:\")\n",
        "    train_df_spark.printSchema()\n",
        "    train_samples_spark = train_df_spark.count()\n",
        "    print(f\"Found {train_samples_spark} training samples after Spark processing.\")\n",
        "\n",
        "print(\"\\nPreprocessing validation annotations with PySpark...\")\n",
        "val_df_spark = preprocess_annotations_spark(val_csv_hdfs_path, val_dir_hdfs)\n",
        "if val_df_spark:\n",
        "    val_df_spark.show(5, truncate=False)\n",
        "    print(f\"Validation DataFrame schema:\")\n",
        "    val_df_spark.printSchema()\n",
        "    val_samples_spark = val_df_spark.count()\n",
        "    print(f\"Found {val_samples_spark} validation samples after Spark processing.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c28505b3",
      "metadata": {},
      "source": [
        "### Cell 4: Data Preparation for PyTorch\n",
        "Convert Spark DataFrames to Pandas DataFrames or list of dicts for the PyTorch Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daaa0194",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Data Preparation for PyTorch\n",
        "train_data_pytorch = []\n",
        "val_data_pytorch = []\n",
        "\n",
        "if train_df_spark:\n",
        "    print(\"\\nCollecting training data for PyTorch...\")\n",
        "    train_data_list = train_df_spark.collect() \n",
        "    train_data_pytorch = [\n",
        "        {\"ImageId\": row.ImageId, \"image_path_hdfs\": row.image_path_hdfs, \"bboxes\": [bbox.asDict() for bbox in row.bboxes] if row.bboxes else []} # Changed dict(bbox) to bbox.asDict()\n",
        "        for row in train_data_list\n",
        "        if row.ImageId is not None and row.image_path_hdfs is not None \n",
        "    ]\n",
        "    print(f\"Collected {len(train_data_pytorch)} training records for PyTorch.\")\n",
        "    if train_data_pytorch:\n",
        "        print(\"Sample PyTorch training record:\", train_data_pytorch[0])\n",
        "else:\n",
        "    print(\"Skipping PyTorch training data preparation due to Spark errors or no data.\")\n",
        "\n",
        "if val_df_spark:\n",
        "    print(\"\\nCollecting validation data for PyTorch...\")\n",
        "    val_data_list = val_df_spark.collect()\n",
        "    val_data_pytorch = [\n",
        "        {\"ImageId\": row.ImageId, \"image_path_hdfs\": row.image_path_hdfs, \"bboxes\": [bbox.asDict() for bbox in row.bboxes] if row.bboxes else []} # Changed dict(bbox) to bbox.asDict()\n",
        "        for row in val_data_list\n",
        "        if row.ImageId is not None and row.image_path_hdfs is not None \n",
        "    ]\n",
        "    print(f\"Collected {len(val_data_pytorch)} validation records for PyTorch.\")\n",
        "    if val_data_pytorch:\n",
        "        print(\"Sample PyTorch validation record:\", val_data_pytorch[0])\n",
        "else:\n",
        "    print(\"Skipping PyTorch validation data preparation due to Spark errors or no data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0caed55d",
      "metadata": {},
      "source": [
        "### Cell 5: Custom PyTorch Dataset Class (`SpaceDebrisDatasetPyTorch`)\n",
        "This dataset takes the preprocessed list of dictionaries (from Spark), an HDFS client, and image directory to load images from HDFS and apply transforms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14fc5313",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Custom PyTorch Dataset Class\n",
        "class SpaceDebrisDatasetPyTorch(Dataset):\n",
        "    def __init__(self, data_records, hdfs_client, transforms=None):\n",
        "        self.data_records = data_records\n",
        "        self.hdfs_client = hdfs_client\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_records)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        record = self.data_records[idx]\n",
        "        img_path_hdfs = record['image_path_hdfs']\n",
        "        img_id = record.get('ImageId', f'index_{idx}') \n",
        "\n",
        "        if not img_path_hdfs or not self.hdfs_client:\n",
        "            print(f\"Skipping sample for img_id {img_id}: Missing HDFS path or HDFS client.\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # Corrected: Removed encoding and errors arguments for binary file reading\n",
        "            with self.hdfs_client.read(img_path_hdfs) as reader: \n",
        "                img_bytes = reader.read() \n",
        "            if not img_bytes:\n",
        "                print(f\"Warning: Image {img_id} from HDFS path {img_path_hdfs} is empty. Returning None.\")\n",
        "                return None\n",
        "            image = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: Image file not found on HDFS for {img_id} at path {img_path_hdfs}. Returning None.\")\n",
        "            return None\n",
        "        except TypeError as te: # Specifically catch TypeError from read() if arguments are still an issue\n",
        "            print(f\"TypeError loading/reading image {img_id} from HDFS path {img_path_hdfs}: {te}. This might indicate an issue with the hdfs library version or arguments.\")\n",
        "            traceback.print_exc() # Print traceback for TypeError\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading/reading image {img_id} from HDFS path {img_path_hdfs}: {e}\")\n",
        "            traceback.print_exc() # Print traceback for other errors\n",
        "            return None \n",
        "\n",
        "        boxes_data = record.get('bboxes', [])\n",
        "        boxes = []\n",
        "        for box_info in boxes_data:\n",
        "            if not isinstance(box_info, dict) or not all(k in box_info for k in ['xmin', 'ymin', 'xmax', 'ymax']):\n",
        "                continue\n",
        "            # The UDF now ensures box_info has keys 'xmin', 'ymin', 'xmax', 'ymax'\n",
        "            # We extract them directly for the model's required [xmin, ymin, xmax, ymax] format\n",
        "            x_min, y_min, x_max, y_max = box_info['xmin'], box_info['ymin'], box_info['xmax'], box_info['ymax']\n",
        "            if x_max > x_min and y_max > y_min: \n",
        "                boxes.append([float(x_min), float(y_min), float(x_max), float(y_max)]) \n",
        "        \n",
        "        num_objs = len(boxes)\n",
        "        target = {}\n",
        "\n",
        "        if num_objs > 0:\n",
        "            target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "            target[\"labels\"] = torch.ones((num_objs,), dtype=torch.int64) \n",
        "            target[\"image_id\"] = torch.tensor([idx])\n",
        "            area = (target[\"boxes\"][:, 3] - target[\"boxes\"][:, 1]) * (target[\"boxes\"][:, 2] - target[\"boxes\"][:, 0])\n",
        "            target[\"area\"] = area\n",
        "            target[\"iscrowd\"] = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "            if torch.any(target['area'] <= 0):\n",
        "                 print(f\"Warning: Zero or negative area detected in boxes for image {img_id} (idx {idx}). Boxes: {target['boxes']}. Returning None.\")\n",
        "                 return None\n",
        "        else: \n",
        "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            target[\"labels\"] = torch.zeros(0, dtype=torch.int64)\n",
        "            target[\"image_id\"] = torch.tensor([idx])\n",
        "            target[\"area\"] = torch.zeros(0, dtype=torch.float32)\n",
        "            target[\"iscrowd\"] = torch.zeros(0, dtype=torch.int64)\n",
        "\n",
        "        image_tensor = None\n",
        "        if self.transforms:\n",
        "            try:\n",
        "                image_tensor = self.transforms(image)\n",
        "            except Exception as e:\n",
        "                print(f\"Error applying transforms to image {img_id}: {e}\")\n",
        "                return None\n",
        "        else:\n",
        "            image_tensor = T.ToTensor()(image) \n",
        "\n",
        "        if not isinstance(image_tensor, torch.Tensor):\n",
        "            print(f\"Warning: Image for index {idx} ({img_id}) is not a Tensor after transforms (type: {type(image_tensor)}). Returning None.\")\n",
        "            return None\n",
        "            \n",
        "        return image_tensor, target"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51549762",
      "metadata": {},
      "source": [
        "### Cell 6: Transforms (`get_transform`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bebc387",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Transforms (Using v1 API)\n",
        "def get_transform(train):\n",
        "    transforms_list = []\n",
        "    transforms_list.append(T.ToTensor())\n",
        "    if train:\n",
        "        transforms_list.append(T.RandomHorizontalFlip(0.5))\n",
        "    return T.Compose(transforms_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b07ff381",
      "metadata": {},
      "source": [
        "### Cell 7: Model Definition (`get_object_detection_model`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fdff8c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Model Definition\n",
        "def get_object_detection_model(num_classes):\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=torchvision.models.detection.FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5acbc52d",
      "metadata": {},
      "source": [
        "### Cell 8: Collate Function (`collate_fn`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eedffd4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Collate Function for DataLoader\n",
        "def collate_fn(batch):\n",
        "    batch = list(filter(lambda x: x is not None, batch))\n",
        "    if not batch: \n",
        "        return None, None \n",
        "    return tuple(zip(*batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f777bb2",
      "metadata": {},
      "source": [
        "### Cell 9: Create Datasets, HDFS Client, and DataLoaders for PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a5c1328",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 9: Create Datasets, HDFS Client, and DataLoaders for PyTorch\n",
        "hdfs_torch_client = None\n",
        "train_dataset_pytorch = None\n",
        "val_dataset_pytorch = None\n",
        "train_loader = None\n",
        "val_loader = None\n",
        "\n",
        "try:\n",
        "    print(f\"Attempting to connect to WebHDFS at {webhdfs_url} as user '{hdfs_user}' for PyTorch image loading...\")\n",
        "    hdfs_torch_client = InsecureClient(webhdfs_url, user=hdfs_user, timeout=10) \n",
        "    hdfs_torch_client.status(base_hdfs_path.rstrip('/') + '/', strict=False) \n",
        "    print(f\"Successfully connected WebHDFS client for PyTorch. Base path '{base_hdfs_path}' status check successful.\")\n",
        "except requests.exceptions.ConnectionError as ce:\n",
        "    print(f\"WebHDFS Connection Error: Failed to connect to {webhdfs_url}. Ensure WebHDFS is running and accessible. Error: {ce}\")\n",
        "    traceback.print_exc()\n",
        "    hdfs_torch_client = None\n",
        "except Exception as e:\n",
        "    print(f\"Error connecting or checking status with WebHDFS client for PyTorch: {e}\")\n",
        "    traceback.print_exc()\n",
        "    hdfs_torch_client = None \n",
        "\n",
        "if hdfs_torch_client and train_data_pytorch and val_data_pytorch:\n",
        "    print(\"\\nCreating PyTorch Training Dataset...\")\n",
        "    train_dataset_pytorch = SpaceDebrisDatasetPyTorch(train_data_pytorch, hdfs_torch_client, get_transform(train=True))\n",
        "    print(\"Creating PyTorch Validation Dataset...\")\n",
        "    val_dataset_pytorch = SpaceDebrisDatasetPyTorch(val_data_pytorch, hdfs_torch_client, get_transform(train=False))\n",
        "\n",
        "    if len(train_dataset_pytorch) > 0 and len(val_dataset_pytorch) > 0:\n",
        "        print(f\"\\nPyTorch Training samples: {len(train_dataset_pytorch)}\")\n",
        "        print(f\"PyTorch Validation samples: {len(val_dataset_pytorch)}\")\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset_pytorch,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            shuffle=True,\n",
        "            num_workers=PYTORCH_NUM_WORKERS,\n",
        "            collate_fn=collate_fn,\n",
        "            pin_memory=True if DEVICE.type == 'cuda' else False \n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset_pytorch,\n",
        "            batch_size=1, \n",
        "            shuffle=False,\n",
        "            num_workers=PYTORCH_NUM_WORKERS,\n",
        "            collate_fn=collate_fn,\n",
        "            pin_memory=True if DEVICE.type == 'cuda' else False\n",
        "        )\n",
        "        print(\"\\nPyTorch DataLoaders created.\")\n",
        "    else:\n",
        "        print(\"\\nOne or both PyTorch datasets are empty after filtering or due to earlier errors. Cannot create DataLoaders.\")\n",
        "        if not train_data_pytorch: print(\"Train data for PyTorch is empty.\")\n",
        "        if not val_data_pytorch: print(\"Validation data for PyTorch is empty.\")\n",
        "elif not hdfs_torch_client:\n",
        "    print(\"\\nCannot create PyTorch datasets: HDFS client for PyTorch is not available.\")\n",
        "else:\n",
        "    print(\"\\nCannot create PyTorch datasets: Spark preprocessing did not yield data, or data was empty.\")\n",
        "\n",
        "if train_dataset_pytorch and len(train_dataset_pytorch) > 0:\n",
        "    print(\"\\nAttempting to display a sample from PyTorch training set...\")\n",
        "    sample_displayed = False\n",
        "    for i in range(min(len(train_dataset_pytorch), 5)): \n",
        "        try:\n",
        "            sample_data = train_dataset_pytorch[i]\n",
        "            if sample_data is not None:\n",
        "                img_tensor, target_dict = sample_data\n",
        "                if img_tensor is not None and target_dict is not None:\n",
        "                    img_pil = T.ToPILImage()(img_tensor)\n",
        "                    plt.figure(figsize=(8, 8))\n",
        "                    ax = plt.gca()\n",
        "                    ax.imshow(img_pil)\n",
        "                    if 'boxes' in target_dict and len(target_dict['boxes']) > 0:\n",
        "                        for box in target_dict['boxes'].cpu().numpy():\n",
        "                            xmin, ymin, xmax, ymax = box\n",
        "                            rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, \n",
        "                                                   linewidth=1, edgecolor='r', facecolor='none')\n",
        "                            ax.add_patch(rect)\n",
        "                    plt.title(f\"Sample Image from PyTorch Dataset (Attempted Index {i})\")\n",
        "                    plt.axis('off')\n",
        "                    plt.show()\n",
        "                    sample_displayed = True\n",
        "                    break \n",
        "        except Exception as e:\n",
        "            print(f\"Error displaying sample at index {i} from PyTorch dataset: {e}\")\n",
        "    if not sample_displayed:\n",
        "        print(\"Could not display any valid sample from the first few items of the PyTorch training dataset.\")\n",
        "elif train_loader is None: \n",
        "     print(\"\\nPyTorch Training dataset is empty or not created, cannot display sample.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd123db4",
      "metadata": {},
      "source": [
        "### Cell 10: Training Loop\n",
        "Handles model training, checkpoint saving/loading, and loss tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aef81432",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 10: Training Loop\n",
        "model = get_object_detection_model(NUM_CLASSES)\n",
        "model.to(DEVICE)\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5) \n",
        "\n",
        "all_train_losses = [] \n",
        "trained_epochs_losses = {} \n",
        "\n",
        "if train_loader is None or val_loader is None:\n",
        "    print(\"DataLoaders are not initialized. Skipping training loop.\")\n",
        "else:\n",
        "    print(f\"Starting training for {NUM_EPOCHS} epochs...\")\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model_checkpoint_path = os.path.join(model_save_dir, f'fasterrcnn_debris_epoch_{epoch+1}.pth')\n",
        "\n",
        "        if os.path.exists(model_checkpoint_path):\n",
        "            print(f\"Checkpoint for epoch {epoch+1} already exists at {model_checkpoint_path}. Skipping training for this epoch.\")\n",
        "            try:\n",
        "                checkpoint_data = torch.load(model_checkpoint_path, map_location='cpu')\n",
        "                loaded_loss = checkpoint_data.get('loss', None)\n",
        "                all_train_losses.append(loaded_loss) \n",
        "                if loaded_loss is not None:\n",
        "                     trained_epochs_losses[epoch + 1] = loaded_loss\n",
        "            except Exception as e:\n",
        "                print(f\"Could not load loss from checkpoint {model_checkpoint_path}: {e}. Appending None.\")\n",
        "                all_train_losses.append(None)\n",
        "            if lr_scheduler: lr_scheduler.step() \n",
        "            continue \n",
        "\n",
        "        model.train()\n",
        "        train_loss_accum = 0.0\n",
        "        num_train_batches = 0\n",
        "        \n",
        "        progress_bar_train = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Training]\")\n",
        "        for batch_idx, (images, targets) in enumerate(progress_bar_train):\n",
        "            if images is None or targets is None: \n",
        "                print(f\"Skipping a batch in epoch {epoch+1} (batch index {batch_idx}) due to collation error or empty batch.\")\n",
        "                continue\n",
        "            \n",
        "            images = list(img.to(DEVICE) for img in images)\n",
        "            targets = [{k: v.to(DEVICE) if isinstance(v, torch.Tensor) else v for k, v in t.items()} for t in targets]\n",
        "            \n",
        "            try:\n",
        "                loss_dict = model(images, targets)\n",
        "                losses = sum(loss for loss in loss_dict.values())\n",
        "                loss_value = losses.item()\n",
        "\n",
        "                if not np.isfinite(loss_value):\n",
        "                    print(f\"Epoch {epoch+1}, Batch {batch_idx}: Non-finite loss detected: {loss_value}. Skipping batch.\")\n",
        "                    continue\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                losses.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP_NORM)\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss_accum += loss_value\n",
        "                num_train_batches += 1\n",
        "                progress_bar_train.set_postfix(loss=f'{loss_value:.4f}')\n",
        "            except RuntimeError as e:\n",
        "                if \"CUDA out of memory\" in str(e):\n",
        "                    print(f\"CUDA out of memory during training epoch {epoch+1}, batch {batch_idx}. Try reducing batch size.\")\n",
        "                    torch.cuda.empty_cache()\n",
        "                    continue \n",
        "                else:\n",
        "                    print(f\"Runtime error during training epoch {epoch+1}, batch {batch_idx}: {e}\")\n",
        "                    traceback.print_exc()\n",
        "                    continue \n",
        "            except Exception as e:\n",
        "                print(f\"An unexpected error occurred during training batch {batch_idx} in epoch {epoch+1}: {e}\")\n",
        "                traceback.print_exc()\n",
        "                continue\n",
        "\n",
        "        if lr_scheduler:\n",
        "            lr_scheduler.step()\n",
        "\n",
        "        avg_train_loss = train_loss_accum / num_train_batches if num_train_batches > 0 else float('nan') \n",
        "        all_train_losses.append(avg_train_loss)\n",
        "        if num_train_batches > 0:\n",
        "             trained_epochs_losses[epoch + 1] = avg_train_loss\n",
        "        \n",
        "        epoch_duration = time.time() - epoch_start_time\n",
        "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} [Training] - Avg Loss: {avg_train_loss:.4f}, Duration: {epoch_duration:.2f}s, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "        try:\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': avg_train_loss,\n",
        "                'scheduler_state_dict': lr_scheduler.state_dict() if lr_scheduler else None\n",
        "            }, model_checkpoint_path)\n",
        "            print(f\"Saved checkpoint for epoch {epoch+1} to {model_checkpoint_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving checkpoint for epoch {epoch+1}: {e}\")\n",
        "\n",
        "        model.eval()\n",
        "        val_loss_accum = 0.0\n",
        "        num_val_batches = 0\n",
        "        progress_bar_val = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Validation]\")\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (images, targets) in enumerate(progress_bar_val):\n",
        "                if images is None or targets is None:\n",
        "                    continue\n",
        "                images = list(img.to(DEVICE) for img in images)\n",
        "                targets = [{k: v.to(DEVICE) if isinstance(v, torch.Tensor) else v for k, v in t.items()} for t in targets]\n",
        "                \n",
        "                try:\n",
        "                    loss_dict = model(images, targets) \n",
        "                    losses = sum(loss for loss in loss_dict.values())\n",
        "                    val_loss_accum += losses.item()\n",
        "                    num_val_batches +=1\n",
        "                    progress_bar_val.set_postfix(loss=f'{losses.item():.4f}')\n",
        "                except Exception as e:\n",
        "                    print(f\"Error during validation batch {batch_idx} in epoch {epoch+1}: {e}\")\n",
        "                    continue\n",
        "                    \n",
        "        avg_val_loss = val_loss_accum / num_val_batches if num_val_batches > 0 else float('nan')\n",
        "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} [Validation] - Avg Loss: {avg_val_loss:.4f}\")\n",
        "        \n",
        "    print(\"\\nTraining finished.\")\n",
        "\n",
        "if 'spark' in globals() and spark.getActiveSession():\n",
        "    print(\"Stopping Spark session at the end of the notebook.\")\n",
        "    spark.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad1ce2d5",
      "metadata": {},
      "source": [
        "### Cell 11: Plot Training Loss\n",
        "Plot the average training loss for epochs that were actually trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2475af19",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 11: Plot Training Loss\n",
        "if trained_epochs_losses:\n",
        "    plot_epochs = []\n",
        "    plot_losses = []\n",
        "    for epoch, loss in sorted(trained_epochs_losses.items()):\n",
        "        if loss is not None and not np.isnan(loss):\n",
        "            plot_epochs.append(epoch)\n",
        "            plot_losses.append(loss)\n",
        "    \n",
        "    if plot_epochs:\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(plot_epochs, plot_losses, marker='o', linestyle='-')\n",
        "        plt.title('Average Training Loss per Trained Epoch')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Average Loss')\n",
        "        plt.xticks(plot_epochs)\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"No valid loss data to plot after filtering.\")\n",
        "elif len(all_train_losses) > 0 and any(l is not None for l in all_train_losses):\n",
        "    epochs_with_data = [i + 1 for i, l in enumerate(all_train_losses) if l is not None and not np.isnan(l)]\n",
        "    losses_with_data = [l for l in all_train_losses if l is not None and not np.isnan(l)]\n",
        "    if epochs_with_data:\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(epochs_with_data, losses_with_data, marker='o', linestyle='-')\n",
        "        plt.title('Average Training Loss (including loaded checkpoints)')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Average Loss')\n",
        "        plt.xticks(epochs_with_data)\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"No valid loss data available from training or checkpoints to plot.\")\n",
        "else:\n",
        "    print(\"No epochs were trained or loss data is unavailable. Cannot plot training loss.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "060e69a2",
      "metadata": {},
      "source": [
        "### Cell 12: Evaluation (Simplified)\n",
        "Load the latest saved model and perform a simplified evaluation pass (loss on validation set).\n",
        "A full evaluation would typically involve calculating metrics like mAP (mean Average Precision)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "377d34bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 12: Evaluation (Simplified)\n",
        "latest_epoch_for_eval = 0\n",
        "eval_model_path = None\n",
        "\n",
        "if os.path.exists(model_save_dir):\n",
        "    for epoch_num in range(NUM_EPOCHS, 0, -1): \n",
        "        path = os.path.join(model_save_dir, f'fasterrcnn_debris_epoch_{epoch_num}.pth')\n",
        "        if os.path.exists(path):\n",
        "            latest_epoch_for_eval = epoch_num\n",
        "            eval_model_path = path\n",
        "            break\n",
        "\n",
        "if latest_epoch_for_eval > 0 and eval_model_path and val_loader is not None:\n",
        "    print(f\"\\nLoading model from epoch {latest_epoch_for_eval} ({eval_model_path}) for evaluation...\")\n",
        "    \n",
        "    eval_model = get_object_detection_model(NUM_CLASSES)\n",
        "    try:\n",
        "        checkpoint = torch.load(eval_model_path, map_location=DEVICE)\n",
        "        eval_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        eval_model.to(DEVICE)\n",
        "        eval_model.eval()\n",
        "        \n",
        "        total_eval_loss = 0\n",
        "        eval_batches = 0\n",
        "        print(\"Running evaluation on the validation set...\")\n",
        "        with torch.no_grad():\n",
        "            for images, targets in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "                if images is None or targets is None: continue\n",
        "                images = list(img.to(DEVICE) for img in images)\n",
        "                targets = [{k: v.to(DEVICE) if isinstance(v, torch.Tensor) else v for k, v in t.items()} for t in targets]\n",
        "                \n",
        "                loss_dict = eval_model(images, targets)\n",
        "                losses = sum(loss for loss in loss_dict.values())\n",
        "                total_eval_loss += losses.item()\n",
        "                eval_batches += 1\n",
        "                \n",
        "        avg_eval_loss = total_eval_loss / eval_batches if eval_batches > 0 else float('nan')\n",
        "        print(f\"Average Validation Loss (Epoch {latest_epoch_for_eval} model): {avg_eval_loss:.4f}\")\n",
        "        print(\"Simplified evaluation (loss only). For mAP, further implementation is needed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during evaluation with model {eval_model_path}: {e}\")\n",
        "        traceback.print_exc()\n",
        "elif not val_loader:\n",
        "    print(\"\\nValidation loader not available, skipping evaluation.\")\n",
        "else:\n",
        "    print(\"\\nNo saved models found in the directory. Skipping evaluation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a596a03f",
      "metadata": {},
      "source": [
        "### Cell 13: Inference on a Single Image\n",
        "Demonstrate how to use the trained model for inference on a single test image from HDFS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23271c2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 13: Inference on a Single Image\n",
        "inference_model = None\n",
        "saved_model_path_for_inference = None\n",
        "latest_trained_epoch_for_inference = 0\n",
        "\n",
        "if os.path.exists(model_save_dir):\n",
        "    for epoch_num in range(NUM_EPOCHS, 0, -1):\n",
        "        path = os.path.join(model_save_dir, f'fasterrcnn_debris_epoch_{epoch_num}.pth')\n",
        "        if os.path.exists(path):\n",
        "            latest_trained_epoch_for_inference = epoch_num\n",
        "            saved_model_path_for_inference = path\n",
        "            break\n",
        "\n",
        "if latest_trained_epoch_for_inference > 0 and saved_model_path_for_inference:\n",
        "    print(f\"\\nLoading model from epoch {latest_trained_epoch_for_inference} for inference from {saved_model_path_for_inference}\")\n",
        "    inference_model = get_object_detection_model(NUM_CLASSES)\n",
        "    try:\n",
        "        checkpoint = torch.load(saved_model_path_for_inference, map_location=DEVICE)\n",
        "        inference_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        inference_model.to(DEVICE)\n",
        "        inference_model.eval()\n",
        "        print(\"Inference model loaded and set to evaluation mode.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading inference model from {saved_model_path_for_inference}: {e}\")\n",
        "        inference_model = None \n",
        "else:\n",
        "    print(\"\\nNo trained model checkpoint found. Cannot perform inference.\")\n",
        "\n",
        "test_image_hdfs_path = None\n",
        "if hdfs_torch_client:\n",
        "    try:\n",
        "        test_dir_hdfs_corrected = test_dir_hdfs.rstrip('/') + '/'\n",
        "        test_image_files = hdfs_torch_client.list(test_dir_hdfs_corrected, status=False)\n",
        "        jpg_files = [f for f in test_image_files if f.lower().endswith('.jpg')]\n",
        "        if jpg_files:\n",
        "            test_image_hdfs_path = f\"{test_dir_hdfs_corrected}{jpg_files[0]}\"\n",
        "            print(f\"Selected test image from HDFS: {test_image_hdfs_path}\")\n",
        "        elif val_data_pytorch and len(val_data_pytorch) > 0:\n",
        "            test_image_hdfs_path = val_data_pytorch[0]['image_path_hdfs']\n",
        "            print(f\"No .jpg files found in HDFS test directory ({test_dir_hdfs_corrected}). Using first validation image for inference: {test_image_hdfs_path}\")\n",
        "        else:\n",
        "            print(f\"No .jpg files in HDFS test directory ({test_dir_hdfs_corrected}) and no validation images available for fallback.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"HDFS test directory {test_dir_hdfs} not found.\")\n",
        "        if val_data_pytorch and len(val_data_pytorch) > 0:\n",
        "            test_image_hdfs_path = val_data_pytorch[0]['image_path_hdfs']\n",
        "            print(f\"Using first validation image for inference: {test_image_hdfs_path}\")\n",
        "        else:\n",
        "             print(\"No validation images available for fallback inference.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error listing test images from HDFS ({test_dir_hdfs}): {e}\")\n",
        "        if val_data_pytorch and len(val_data_pytorch) > 0:\n",
        "            test_image_hdfs_path = val_data_pytorch[0]['image_path_hdfs']\n",
        "            print(f\"Using first validation image for inference due to error: {test_image_hdfs_path}\")\n",
        "\n",
        "def run_inference_on_single_image(model, image_path_hdfs, hdfs_cli, device, conf_threshold=0.5):\n",
        "    if not hdfs_cli:\n",
        "        print(\"HDFS client not available for inference.\")\n",
        "        return None, None, None, None\n",
        "    if not image_path_hdfs:\n",
        "        print(\"Image HDFS path not provided for inference.\")\n",
        "        return None, None, None, None\n",
        "    try:\n",
        "        with hdfs_cli.read(image_path_hdfs) as reader:\n",
        "            img_bytes = reader.read()\n",
        "        if not img_bytes:\n",
        "            print(f\"Image at {image_path_hdfs} was empty.\")\n",
        "            return None, None, None, None\n",
        "        pil_image = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
        "        \n",
        "        img_tensor = T.ToTensor()(pil_image).to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            prediction = model([img_tensor])\n",
        "        \n",
        "        pred_boxes = prediction[0]['boxes'].cpu().numpy()\n",
        "        pred_labels = prediction[0]['labels'].cpu().numpy()\n",
        "        pred_scores = prediction[0]['scores'].cpu().numpy()\n",
        "        \n",
        "        high_conf_indices = pred_scores >= conf_threshold\n",
        "        filtered_boxes = pred_boxes[high_conf_indices]\n",
        "        filtered_labels = pred_labels[high_conf_indices]\n",
        "        filtered_scores = pred_scores[high_conf_indices]\n",
        "        \n",
        "        return pil_image, filtered_boxes, filtered_labels, filtered_scores\n",
        "        \n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Image file not found on HDFS for inference at path {image_path_hdfs}.\")\n",
        "        return None, None, None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error during single image inference for {image_path_hdfs}: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None, None, None, None\n",
        "\n",
        "if inference_model and test_image_hdfs_path and hdfs_torch_client:\n",
        "    print(f\"\\nRunning inference on: {test_image_hdfs_path}\")\n",
        "    confidence_threshold = 0.5\n",
        "    \n",
        "    original_image, boxes, labels, scores = run_inference_on_single_image(\n",
        "        inference_model, \n",
        "        test_image_hdfs_path, \n",
        "        hdfs_torch_client, \n",
        "        DEVICE, \n",
        "        conf_threshold=confidence_threshold\n",
        "    )\n",
        "    \n",
        "    if original_image is not None and boxes is not None:\n",
        "        print(f\"Found {len(boxes)} objects with confidence >= {confidence_threshold}\")\n",
        "        try:\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            ax = plt.gca()\n",
        "            ax.imshow(original_image)\n",
        "            font = ImageFont.load_default() \n",
        "            for i, box in enumerate(boxes):\n",
        "                xmin, ymin, xmax, ymax = box\n",
        "                rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, \n",
        "                                       linewidth=2, edgecolor='lime', facecolor='none')\n",
        "                ax.add_patch(rect)\n",
        "                label_text = f\"Debris: {scores[i]:.2f}\"\n",
        "                ax.text(xmin, ymin - 10, label_text, color='black', fontsize=8, \n",
        "                        bbox=dict(facecolor='lime', alpha=0.7, pad=1))\n",
        "            \n",
        "            plt.title(f\"Inference Result (Confidence >= {confidence_threshold}) on {os.path.basename(test_image_hdfs_path)}\", fontsize=14)\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "        except Exception as e:\n",
        "             print(f\"\\nError visualizing inference result: {e}\")\n",
        "             traceback.print_exc()\n",
        "    else:\n",
        "         print(\"\\nInference function did not return valid results or no objects found.\")\n",
        "else:\n",
        "    print(f\"\\nCannot run single image inference. Check conditions:\")\n",
        "    print(f\"  PyTorch HDFS Client is valid: {hdfs_torch_client is not None}\")\n",
        "    print(f\"  Test image HDFS path is set: {test_image_hdfs_path is not None}\")\n",
        "    print(f\"  Inference model is loaded: {inference_model is not None}\")\n",
        "    if saved_model_path_for_inference:\n",
        "        print(f\"  Saved model path (local) for inference: {saved_model_path_for_inference}\")\n",
        "        print(f\"  Saved model exists: {os.path.exists(saved_model_path_for_inference)}\")\n",
        "    elif latest_trained_epoch_for_inference == 0:\n",
        "        print(f\"  No model checkpoint was found in {model_save_dir}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Bazinga",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
