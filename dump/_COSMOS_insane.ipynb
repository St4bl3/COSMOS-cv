{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe64440e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3060 Laptop GPU, compute capability 8.6\n",
      "Loaded zlibwapi.dll\n",
      "Using 1 GPU(s)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports, Mixed Precision, GPU & DLL Setup, Configuration\n",
    "\n",
    "import os, glob, ctypes\n",
    "import h5py, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, mixed_precision\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score,\n",
    "    f1_score, accuracy_score, mean_squared_error, mean_absolute_error\n",
    ")\n",
    "\n",
    "# Enable mixed precision for speed on GPU\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# DLL fix for Windows HDF5/zlib\n",
    "try:\n",
    "    dll = os.path.join(os.environ['CONDA_PREFIX'], 'Library', 'bin', 'zlibwapi.dll')\n",
    "    ctypes.CDLL(dll)\n",
    "    print(\"Loaded zlibwapi.dll\")\n",
    "except Exception:\n",
    "    print(\"Could not load zlibwapi.dll\")\n",
    "\n",
    "# GPU config\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"Using {len(gpus)} GPU(s)\")\n",
    "else:\n",
    "    print(\"No GPU detected\")\n",
    "\n",
    "# Config — tuned for speed\n",
    "DATA_DIR      = r\"C:\\college\\CV\\COSMOS\\6C_full\"\n",
    "SEQ_LEN       = 4         # use 4 time steps instead of 6\n",
    "PATCH_SIZE    = 32        # use 32×32 patches instead of 64×64\n",
    "BATCH_SIZE    = 16        # larger batch if GPU memory allows\n",
    "EPOCHS        = 10        # max epochs\n",
    "THRESHOLD     = 265.0\n",
    "CV_THRESHOLD  = 260.0\n",
    "FOG_THRESHOLD = 270.0\n",
    "MODEL_PATH    = r\"C:\\college\\CV\\COSMOS\\multitask_nowcast_fast.h5\"\n",
    "\n",
    "# list files & build sliding windows\n",
    "all_files = sorted(glob.glob(os.path.join(DATA_DIR, \"*.h5\")))\n",
    "sequences = [all_files[i:i+SEQ_LEN+1] for i in range(len(all_files)-SEQ_LEN)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f3700",
   "metadata": {},
   "source": [
    "Data-Loading & Generator Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b3f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Data Loader & Generator\n",
    "\n",
    "def load_multi(fp_seq):\n",
    "    frames = []\n",
    "    for fp in fp_seq[:SEQ_LEN]:\n",
    "        with h5py.File(fp,'r') as f:\n",
    "            cnt1, cnt2   = f['IMG_TIR1'][0][...], f['IMG_TIR2'][0][...]\n",
    "            cnt_wv, cnt_mir = f['IMG_WV'][0][...], f['IMG_MIR'][0][...]\n",
    "            cnt_vis      = f['IMG_VIS'][0][...]\n",
    "            lut1, lut2   = f['IMG_TIR1_TEMP'][:],  f['IMG_TIR2_TEMP'][:]\n",
    "            lut_wv, lut_mir = f['IMG_WV_TEMP'][:], f['IMG_MIR_TEMP'][:]\n",
    "            lut_vis      = f['IMG_VIS_ALBEDO'][:]\n",
    "        bt1 = lut1[cnt1]; bt2 = lut2[cnt2]\n",
    "        wv  = lut_wv[cnt_wv]; mir = lut_mir[cnt_mir]\n",
    "        vis = lut_vis[cnt_vis]\n",
    "        frames.append(np.stack([bt1,bt2,wv,mir,vis],axis=-1)/300.0)\n",
    "    X = np.stack(frames,axis=0).astype(np.float32)\n",
    "\n",
    "    with h5py.File(fp_seq[-1],'r') as f:\n",
    "        cnt1, cnt2   = f['IMG_TIR1'][0][...], f['IMG_TIR2'][0][...]\n",
    "        cnt_wv, cnt_mir = f['IMG_WV'][0][...], f['IMG_MIR'][0][...]\n",
    "        lut1, lut2   = f['IMG_TIR1_TEMP'][:],  f['IMG_TIR2_TEMP'][:]\n",
    "        lut_wv, lut_mir = f['IMG_WV_TEMP'][:], f['IMG_MIR_TEMP'][:]\n",
    "    bt1_t = lut1[cnt1]; bt2_t = lut2[cnt2]\n",
    "    wv_t  = lut_wv[cnt_wv]; mir_t = lut_mir[cnt_mir]\n",
    "\n",
    "    # temperature trend normalized\n",
    "    last_mean  = bt1_t.mean()/300.0\n",
    "    first_mean = X[0,...,0].mean()\n",
    "    temp_trend = np.array([last_mean - first_mean],dtype=np.float32)\n",
    "\n",
    "    return X, {\n",
    "        'cloud'          : (bt1_t<THRESHOLD).astype(np.float32)[...,None],\n",
    "        'convective'     : (bt1_t<CV_THRESHOLD).astype(np.float32)[...,None],\n",
    "        'fog'            : (mir_t<FOG_THRESHOLD).astype(np.float32)[...,None],\n",
    "        'moisture'       : (wv_t/300.0).astype(np.float32)[...,None],\n",
    "        'thermo_contrast': ((bt2_t-bt1_t)/100.0).astype(np.float32)[...,None],\n",
    "        'temp_trend'     : temp_trend\n",
    "    }\n",
    "\n",
    "def random_crop(X,y):\n",
    "    H,W = X.shape[1], X.shape[2]\n",
    "    i,j = np.random.randint(0,H-PATCH_SIZE), np.random.randint(0,W-PATCH_SIZE)\n",
    "    Xc = X[:,i:i+PATCH_SIZE,j:j+PATCH_SIZE,:]\n",
    "    yc = {}\n",
    "    for k,v in y.items():\n",
    "        yc[k] = v[i:i+PATCH_SIZE,j:j+PATCH_SIZE] if v.ndim==3 else v\n",
    "    return Xc,yc\n",
    "\n",
    "def generator(seqs):\n",
    "    while True:\n",
    "        np.random.shuffle(seqs)\n",
    "        for seq in seqs:\n",
    "            X,y = load_multi(seq)\n",
    "            yield random_crop(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd47b4",
   "metadata": {},
   "source": [
    "Dataset Split & steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a27a1936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Dataset Split, Caching & Pipelines\n",
    "\n",
    "# train/val split\n",
    "split       = int(0.9*len(sequences))\n",
    "train_seqs  = sequences[:split]\n",
    "val_seqs    = sequences[split:]\n",
    "\n",
    "# steps per epoch\n",
    "train_steps = len(train_seqs)//BATCH_SIZE\n",
    "val_steps   = len(val_seqs)//BATCH_SIZE\n",
    "\n",
    "# common output signature\n",
    "output_signature = (\n",
    "    tf.TensorSpec((SEQ_LEN,PATCH_SIZE,PATCH_SIZE,5),tf.float32),\n",
    "    {\n",
    "      'cloud': tf.TensorSpec((PATCH_SIZE,PATCH_SIZE,1),tf.float32),\n",
    "      'convective': tf.TensorSpec((PATCH_SIZE,PATCH_SIZE,1),tf.float32),\n",
    "      'fog': tf.TensorSpec((PATCH_SIZE,PATCH_SIZE,1),tf.float32),\n",
    "      'moisture': tf.TensorSpec((PATCH_SIZE,PATCH_SIZE,1),tf.float32),\n",
    "      'thermo_contrast': tf.TensorSpec((PATCH_SIZE,PATCH_SIZE,1),tf.float32),\n",
    "      'temp_trend': tf.TensorSpec((1,),tf.float32)\n",
    "    }\n",
    ")\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: generator(train_seqs), output_signature=output_signature\n",
    ").cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: generator(val_seqs), output_signature=output_signature\n",
    ").cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8115447",
   "metadata": {},
   "source": [
    "Cell 4: Model Definition & Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fee617e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fast_multitask_nowcast\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 4, 32, 32,   0           []                               \n",
      "                                5)]                                                               \n",
      "                                                                                                  \n",
      " conv_lstm2d (ConvLSTM2D)       (None, 4, 32, 32, 3  42752       ['input_1[0][0]']                \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 4, 32, 32, 3  128        ['conv_lstm2d[0][0]']            \n",
      " alization)                     2)                                                                \n",
      "                                                                                                  \n",
      " conv_lstm2d_1 (ConvLSTM2D)     (None, 32, 32, 16)   27712       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 16)  64          ['conv_lstm2d_1[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 16)          0           ['batch_normalization_1[0][0]']  \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " cloud (Conv2D)                 (None, 32, 32, 1)    17          ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " convective (Conv2D)            (None, 32, 32, 1)    17          ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " fog (Conv2D)                   (None, 32, 32, 1)    17          ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " moisture (Conv2D)              (None, 32, 32, 1)    17          ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " temp_trend (Dense)             (None, 1)            17          ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " thermo_contrast (Conv2D)       (None, 32, 32, 1)    17          ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 70,758\n",
      "Trainable params: 70,662\n",
      "Non-trainable params: 96\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Model Definition & Compilation\n",
    "\n",
    "inp = layers.Input((SEQ_LEN,PATCH_SIZE,PATCH_SIZE,5))\n",
    "x = layers.ConvLSTM2D(32,(3,3),padding='same',return_sequences=True,activation='relu')(inp)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ConvLSTM2D(16,(3,3),padding='same',return_sequences=False,activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "heads = {\n",
    "  'cloud'          : layers.Conv2D(1,(1,1),activation='sigmoid',   name='cloud')(x),\n",
    "  'convective'     : layers.Conv2D(1,(1,1),activation='sigmoid',   name='convective')(x),\n",
    "  'fog'            : layers.Conv2D(1,(1,1),activation='sigmoid',   name='fog')(x),\n",
    "  'moisture'       : layers.Conv2D(1,(1,1),activation='linear',    name='moisture')(x),\n",
    "  'thermo_contrast': layers.Conv2D(1,(1,1),activation='linear',    name='thermo_contrast')(x),\n",
    "}\n",
    "temp_avg = layers.GlobalAveragePooling2D()(x)\n",
    "heads['temp_trend'] = layers.Dense(1,activation='linear',name='temp_trend')(temp_avg)\n",
    "\n",
    "model = Model(inputs=inp, outputs=heads, name='fast_multitask_nowcast')\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss={\n",
    "    'cloud':'binary_crossentropy','convective':'binary_crossentropy','fog':'binary_crossentropy',\n",
    "    'moisture':'mse','thermo_contrast':'mse','temp_trend':'mse'\n",
    "  },\n",
    "  loss_weights={'cloud':1,'convective':1,'fog':1,'moisture':0.5,'thermo_contrast':0.5,'temp_trend':0.1},\n",
    "  metrics={'cloud':'accuracy','convective':'accuracy','fog':'accuracy'}\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a649438",
   "metadata": {},
   "source": [
    "Training with Progress Bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d21a867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 2.1109 - cloud_loss: 0.5481 - convective_loss: 0.5631 - fog_loss: 0.6219 - moisture_loss: 0.6031 - temp_trend_loss: 0.0396 - thermo_contrast_loss: 0.1443 - cloud_accuracy: 0.7207 - convective_accuracy: 0.7386 - fog_accuracy: 0.6733 \n",
      "Epoch 1: val_cloud_accuracy improved from -inf to 0.73488, saving model to C:\\college\\CV\\COSMOS\\multitask_nowcast_fast.h5\n",
      "50/50 [==============================] - 3098s 62s/step - loss: 2.1109 - cloud_loss: 0.5481 - convective_loss: 0.5631 - fog_loss: 0.6219 - moisture_loss: 0.6031 - temp_trend_loss: 0.0396 - thermo_contrast_loss: 0.1443 - cloud_accuracy: 0.7207 - convective_accuracy: 0.7386 - fog_accuracy: 0.6733 - val_loss: 2.1309 - val_cloud_loss: 0.6645 - val_convective_loss: 0.6556 - val_fog_loss: 0.6675 - val_moisture_loss: 0.2864 - val_temp_trend_loss: 1.7972e-04 - val_thermo_contrast_loss: 0.0014 - val_cloud_accuracy: 0.7349 - val_convective_accuracy: 0.7774 - val_fog_accuracy: 0.7979\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.3953 - cloud_loss: 0.3870 - convective_loss: 0.4033 - fog_loss: 0.4895 - moisture_loss: 0.2066 - temp_trend_loss: 0.0130 - thermo_contrast_loss: 0.0219 - cloud_accuracy: 0.8455 - convective_accuracy: 0.8642 - fog_accuracy: 0.8304 \n",
      "Epoch 2: val_cloud_accuracy did not improve from 0.73488\n",
      "50/50 [==============================] - 3027s 62s/step - loss: 1.3953 - cloud_loss: 0.3870 - convective_loss: 0.4033 - fog_loss: 0.4895 - moisture_loss: 0.2066 - temp_trend_loss: 0.0130 - thermo_contrast_loss: 0.0219 - cloud_accuracy: 0.8455 - convective_accuracy: 0.8642 - fog_accuracy: 0.8304 - val_loss: 2.0719 - val_cloud_loss: 0.6897 - val_convective_loss: 0.6526 - val_fog_loss: 0.6466 - val_moisture_loss: 0.1662 - val_temp_trend_loss: 7.3032e-04 - val_thermo_contrast_loss: 6.7520e-04 - val_cloud_accuracy: 0.4063 - val_convective_accuracy: 0.7609 - val_fog_accuracy: 0.7920\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.1218 - cloud_loss: 0.3162 - convective_loss: 0.3311 - fog_loss: 0.4257 - moisture_loss: 0.0792 - temp_trend_loss: 0.0151 - thermo_contrast_loss: 0.0152 - cloud_accuracy: 0.8873 - convective_accuracy: 0.8965 - fog_accuracy: 0.8728 \n",
      "Epoch 3: val_cloud_accuracy did not improve from 0.73488\n",
      "50/50 [==============================] - 3146s 64s/step - loss: 1.1218 - cloud_loss: 0.3162 - convective_loss: 0.3311 - fog_loss: 0.4257 - moisture_loss: 0.0792 - temp_trend_loss: 0.0151 - thermo_contrast_loss: 0.0152 - cloud_accuracy: 0.8873 - convective_accuracy: 0.8965 - fog_accuracy: 0.8728 - val_loss: 2.1258 - val_cloud_loss: 0.7477 - val_convective_loss: 0.6421 - val_fog_loss: 0.6196 - val_moisture_loss: 0.2310 - val_temp_trend_loss: 0.0065 - val_thermo_contrast_loss: 0.0020 - val_cloud_accuracy: 0.2864 - val_convective_accuracy: 0.8335 - val_fog_accuracy: 0.8031\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.0303 - cloud_loss: 0.3027 - convective_loss: 0.3152 - fog_loss: 0.3835 - moisture_loss: 0.0419 - temp_trend_loss: 0.0113 - thermo_contrast_loss: 0.0138 - cloud_accuracy: 0.8959 - convective_accuracy: 0.9026 - fog_accuracy: 0.8893 "
     ]
    }
   ],
   "source": [
    "# Cell 5: Training\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "  MODEL_PATH, monitor='val_cloud_accuracy',\n",
    "  save_best_only=False, verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=EPOCHS,\n",
    "  steps_per_epoch=train_steps,\n",
    "  validation_steps=val_steps,\n",
    "  callbacks=[checkpoint],\n",
    "  verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21a6144",
   "metadata": {},
   "source": [
    "Evaluation & Metrics Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da45ae29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval Seg: 119it [1:43:57, 51.79s/it]"
     ]
    }
   ],
   "source": [
    "# Cell 6 — Evaluation\n",
    "seg_keys = [\"cloud\",\"convective\",\"fog\"]\n",
    "reg_keys = [\"moisture\",\"thermo_contrast\",\"temp_trend\"]\n",
    "\n",
    "y_true_seg, y_pred_seg = {k:[] for k in seg_keys}, {k:[] for k in seg_keys}\n",
    "y_true_reg, y_pred_reg = {k:[] for k in reg_keys}, {k:[] for k in reg_keys}\n",
    "\n",
    "for Xb, yb in tqdm(val_ds, desc=\"Evaluation\"):\n",
    "    preds = model(Xb, training=False)\n",
    "    for k in seg_keys:\n",
    "        y_true_seg[k].append(tf.reshape(yb[k], (-1,)).numpy())\n",
    "        y_pred_seg[k].append((tf.reshape(preds[k], (-1,)) > 0.5).numpy())\n",
    "    for k in reg_keys:\n",
    "        y_true_reg[k].append(tf.reshape(yb[k], (-1,)).numpy())\n",
    "        y_pred_reg[k].append(tf.reshape(preds[k], (-1,)).numpy())\n",
    "\n",
    "for d in (y_true_seg, y_pred_seg, y_true_reg, y_pred_reg):\n",
    "    for k in d: d[k] = np.concatenate(d[k])\n",
    "\n",
    "# ── segmentation --------------------------------------------------------------\n",
    "seg_rows=[]\n",
    "for k in seg_keys:\n",
    "    cm = confusion_matrix(y_true_seg[k], y_pred_seg[k])\n",
    "    seg_rows.append({\"Task\":k,\n",
    "                     \"Acc\":accuracy_score(y_true_seg[k], y_pred_seg[k]),\n",
    "                     \"Prec\":precision_score(y_true_seg[k], y_pred_seg[k], zero_division=0),\n",
    "                     \"Rec\":recall_score(y_true_seg[k], y_pred_seg[k], zero_division=0),\n",
    "                     \"F1\":f1_score(y_true_seg[k], y_pred_seg[k], zero_division=0),\n",
    "                     \"TN\":cm[0,0],\"FP\":cm[0,1],\"FN\":cm[1,0],\"TP\":cm[1,1]})\n",
    "df_seg = pd.DataFrame(seg_rows).set_index(\"Task\")\n",
    "print(\"### Segmentation\"); display(df_seg)\n",
    "\n",
    "# ── regression ----------------------------------------------------------------\n",
    "reg_rows=[]\n",
    "for k in reg_keys:\n",
    "    reg_rows.append({\"Task\":k,\n",
    "                     \"MSE\":mean_squared_error(y_true_reg[k], y_pred_reg[k]),\n",
    "                     \"MAE\":mean_absolute_error(y_true_reg[k], y_pred_reg[k])})\n",
    "df_reg = pd.DataFrame(reg_rows).set_index(\"Task\")\n",
    "print(\"### Regression\"); display(df_reg)\n",
    "\n",
    "# ── confusion matrices --------------------------------------------------------\n",
    "for k in seg_keys:\n",
    "    cm = confusion_matrix(y_true_seg[k], y_pred_seg[k])\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.title(f\"{k.capitalize()} – Confusion matrix\")\n",
    "    plt.imshow(cm, cmap=\"Blues\"); plt.xlabel(\"Pred\"); plt.ylabel(\"True\")\n",
    "    for (i,j),v in np.ndenumerate(cm): plt.text(j,i,str(v), ha=\"center\", va=\"center\")\n",
    "    plt.colorbar(); plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
