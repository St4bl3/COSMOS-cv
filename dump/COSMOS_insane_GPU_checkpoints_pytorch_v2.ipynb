{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a70d6140",
   "metadata": {},
   "source": [
    "# PyTorch GPU version of COSMOS multi‑task nowcast\n",
    "This notebook replicates the original TensorFlow implementation but runs fully on **PyTorch** with GPU support (CUDA, mixed‑precision). Functionality and results should be equivalent.\n",
    "\n",
    "*GPU in use will be automatically detected; if you have installed CUDA correctly, training should take place on your RTX 3060.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "648cee13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "Total sequences: 896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhanu\\AppData\\Local\\Temp\\ipykernel_18660\\3654101961.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports, GPU & Mixed‑Precision Setup\n",
    "\n",
    "import os, glob, h5py, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (confusion_matrix, precision_score, recall_score,\n",
    "                             f1_score, accuracy_score, mean_squared_error, mean_absolute_error)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Running on device: {device}')\n",
    "\n",
    "torch.backends.cudnn.benchmark = True        # speed\n",
    "# optional: allow TF‑like float16 mixed precision\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Configuration (identical to original)\n",
    "DATA_DIR      = r\"C:\\college\\CV\\COSMOS\\6C_full\"\n",
    "SEQ_LEN       = 4\n",
    "PATCH_SIZE    = 32\n",
    "BATCH_SIZE    = 16\n",
    "EPOCHS        = 20\n",
    "THRESHOLD     = 265.0\n",
    "CV_THRESHOLD  = 260.0\n",
    "FOG_THRESHOLD = 270.0\n",
    "\n",
    "MODEL_DIR     = \"checkpoints_pytorch\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Build list of sliding‑window sequences\n",
    "all_files = sorted(glob.glob(os.path.join(DATA_DIR, \"*.h5\")))\n",
    "sequences = [all_files[i:i+SEQ_LEN+1] for i in range(len(all_files)-SEQ_LEN)]\n",
    "print(f\"Total sequences: {len(sequences)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aca5caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset utilities ----------------------------------------------------------\n",
    "def load_multi(fp_seq):\n",
    "    frames = []\n",
    "    for fp in fp_seq[:SEQ_LEN]:\n",
    "        with h5py.File(fp,'r') as f:\n",
    "            cnt1, cnt2   = f['IMG_TIR1'][0][...], f['IMG_TIR2'][0][...]\n",
    "            cnt_wv, cnt_mir = f['IMG_WV'][0][...], f['IMG_MIR'][0][...]\n",
    "            cnt_vis      = f['IMG_VIS'][0][...]\n",
    "            lut1, lut2   = f['IMG_TIR1_TEMP'][:],  f['IMG_TIR2_TEMP'][:]\n",
    "            lut_wv, lut_mir = f['IMG_WV_TEMP'][:], f['IMG_MIR_TEMP'][:]\n",
    "            lut_vis      = f['IMG_VIS_ALBEDO'][:]\n",
    "        bt1 = lut1[cnt1]; bt2 = lut2[cnt2]\n",
    "        wv  = lut_wv[cnt_wv]; mir = lut_mir[cnt_mir]\n",
    "        vis = lut_vis[cnt_vis]\n",
    "        frames.append(np.stack([bt1,bt2,wv,mir,vis],axis=-1)/300.0)      # Normalise\n",
    "\n",
    "    X = np.stack(frames,axis=0).astype(np.float32)\n",
    "\n",
    "    # Labels come from final frame in sequence\n",
    "    with h5py.File(fp_seq[-1],'r') as f:\n",
    "        cnt1, cnt2   = f['IMG_TIR1'][0][...], f['IMG_TIR2'][0][...]\n",
    "        cnt_wv, cnt_mir = f['IMG_WV'][0][...], f['IMG_MIR'][0][...]\n",
    "        lut1, lut2   = f['IMG_TIR1_TEMP'][:],  f['IMG_TIR2_TEMP'][:]\n",
    "        lut_wv, lut_mir = f['IMG_WV_TEMP'][:], f['IMG_MIR_TEMP'][:]\n",
    "    bt1_t = lut1[cnt1]; bt2_t = lut2[cnt2]\n",
    "    wv_t  = lut_wv[cnt_wv]; mir_t = lut_mir[cnt_mir]\n",
    "\n",
    "    last_mean  = bt1_t.mean()/300.0\n",
    "    first_mean = X[0,...,0].mean()\n",
    "    temp_trend = np.array([last_mean - first_mean],dtype=np.float32)\n",
    "\n",
    "    labels = {\n",
    "        'cloud'          : (bt1_t<THRESHOLD).astype(np.float32)[...,None],\n",
    "        'convective'     : (bt1_t<CV_THRESHOLD).astype(np.float32)[...,None],\n",
    "        'fog'            : (mir_t<FOG_THRESHOLD).astype(np.float32)[...,None],\n",
    "        'moisture'       : (wv_t/300.0).astype(np.float32)[...,None],\n",
    "        'thermo_contrast': ((bt2_t-bt1_t)/100.0).astype(np.float32)[...,None],\n",
    "        'temp_trend'     : temp_trend\n",
    "    }\n",
    "    return X, labels\n",
    "\n",
    "def random_crop(X, y):\n",
    "    H,W = X.shape[1], X.shape[2]\n",
    "    i = np.random.randint(0, H-PATCH_SIZE)\n",
    "    j = np.random.randint(0, W-PATCH_SIZE)\n",
    "    Xc = X[:, i:i+PATCH_SIZE, j:j+PATCH_SIZE, :]\n",
    "    yc = {}\n",
    "    for k,v in y.items():\n",
    "        yc[k] = v[i:i+PATCH_SIZE, j:j+PATCH_SIZE] if v.ndim==3 else v\n",
    "    return Xc, yc\n",
    "\n",
    "class PatchDataset(IterableDataset):\n",
    "    \"\"\"Yields infinite random crops exactly like the TF generator.\"\"\"\n",
    "    def __init__(self, seqs):\n",
    "        super().__init__()\n",
    "        self.seqs = seqs\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            np.random.shuffle(self.seqs)\n",
    "            for seq in self.seqs:\n",
    "                X, y = load_multi(seq)\n",
    "                Xc, yc = random_crop(X, y)\n",
    "                # convert to tensors\n",
    "                Xc = torch.from_numpy(Xc).permute(0,3,1,2)        # (T,C,H,W)\n",
    "                targets = {\n",
    "                    k: torch.from_numpy(v).permute(2,0,1) if v.ndim==3 else torch.from_numpy(v)\n",
    "                    for k,v in yc.items()\n",
    "                }\n",
    "                yield Xc, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e7cf878",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DataLoader construction ----------------------------------------------------\n",
    "import torch.multiprocessing as mp\n",
    "mp.set_start_method('spawn', force=True)\n",
    "\n",
    "split = int(0.9*len(sequences))\n",
    "train_seqs = sequences[:split]\n",
    "val_seqs   = sequences[split:]\n",
    "\n",
    "train_dataset = PatchDataset(train_seqs)\n",
    "val_dataset   = PatchDataset(val_seqs)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0,            # use single process to avoid HDF5 deadlocks\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f5fcddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 0.07M\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model definition -----------------------------------------------------------\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        padding = kernel_size//2\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.conv = nn.Conv2d(input_channels + hidden_channels,\n",
    "                              4*hidden_channels, kernel_size,\n",
    "                              padding=padding, bias=True)\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        combined = torch.cat([x, h_prev], dim=1)\n",
    "        gates = self.conv(combined)\n",
    "        i, f, o, g = gates.chunk(4, dim=1)\n",
    "        i = torch.sigmoid(i); f = torch.sigmoid(f)\n",
    "        o = torch.sigmoid(o); g = torch.tanh(g)\n",
    "        c = f * c_prev + i * g\n",
    "        h = o * torch.tanh(c)\n",
    "        return h, c\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    \"\"\"Multi-step ConvLSTM with optional sequence output.\"\"\"\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size=3, return_sequences=False):\n",
    "        super().__init__()\n",
    "        self.cell = ConvLSTMCell(input_channels, hidden_channels, kernel_size)\n",
    "        self.return_sequences = return_sequences\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, C, H, W)\n",
    "        B, T, C, H, W = x.shape\n",
    "        h = torch.zeros(B, self.cell.hidden_channels, H, W, device=x.device)\n",
    "        c = torch.zeros_like(h)\n",
    "        seq_out = []\n",
    "        for t in range(T):\n",
    "            h, c = self.cell(x[:, t], h, c)\n",
    "            if self.return_sequences:\n",
    "                seq_out.append(h)\n",
    "        if self.return_sequences:\n",
    "            return torch.stack(seq_out, dim=1)  # (B, T, hidden, H, W)\n",
    "        else:\n",
    "            return h  # (B, hidden, H, W)\n",
    "\n",
    "class MultiTaskNowcast(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convlstm1 = ConvLSTM(5, 32, return_sequences=True)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.convlstm2 = ConvLSTM(32, 16, return_sequences=False)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.heads = nn.ModuleDict({\n",
    "            'cloud'          : nn.Conv2d(16,1,1),\n",
    "            'convective'     : nn.Conv2d(16,1,1),\n",
    "            'fog'            : nn.Conv2d(16,1,1),\n",
    "            'moisture'       : nn.Conv2d(16,1,1),\n",
    "            'thermo_contrast': nn.Conv2d(16,1,1),\n",
    "        })\n",
    "        self.temp_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.temp_fc   = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, C, H, W)\n",
    "        x = self.convlstm1(x)  # (B, T, 32, H, W)\n",
    "        # apply batchnorm to each time step separately\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.reshape(B*T, C, H, W)\n",
    "        x = self.bn1(x)\n",
    "        x = x.reshape(B, T, C, H, W)\n",
    "        x = self.convlstm2(x)  # (B, 16, H, W)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        out = {}\n",
    "        for k, layer in self.heads.items():\n",
    "            if k in ['moisture', 'thermo_contrast']:\n",
    "                out[k] = layer(x).squeeze(1)\n",
    "            else:\n",
    "                out[k] = layer(x)\n",
    "        temp_feat = self.temp_pool(x).flatten(1)\n",
    "        out['temp_trend'] = self.temp_fc(temp_feat)\n",
    "        return out\n",
    "\n",
    "model = MultiTaskNowcast().to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2479eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Losses, optimizer, metrics -----------------------------------------------\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "mse = nn.MSELoss()\n",
    "loss_weights = {'cloud':1,'convective':1,'fog':1,'moisture':0.5,'thermo_contrast':0.5,'temp_trend':0.1}\n",
    "\n",
    "def compute_loss(preds, targets):\n",
    "    loss = 0.0\n",
    "    for k, w in loss_weights.items():\n",
    "        if k in ['cloud','convective','fog']:\n",
    "            loss += w * bce(preds[k].float(), targets[k].float())\n",
    "        else:\n",
    "            loss += w * mse(preds[k].float().squeeze(), targets[k].float().squeeze())\n",
    "    return loss\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c30f650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [train]:   2%|▏         | 1/50 [02:15<1:50:30, 135.31s/it, loss=2.88]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 749. MiB for an array with shape (4, 3207, 3062, 5) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m train_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_loader)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m---> 13\u001b[0m     Xb, yb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     Xb \u001b[38;5;241m=\u001b[39m Xb\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m     yb \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m yb\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\w\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\w\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\w\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:33\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 62\u001b[0m, in \u001b[0;36mPatchDataset.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseqs)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseqs:\n\u001b[1;32m---> 62\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[43mload_multi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     Xc, yc \u001b[38;5;241m=\u001b[39m random_crop(X, y)\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# convert to tensors\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 17\u001b[0m, in \u001b[0;36mload_multi\u001b[1;34m(fp_seq)\u001b[0m\n\u001b[0;32m     14\u001b[0m     vis \u001b[38;5;241m=\u001b[39m lut_vis[cnt_vis]\n\u001b[0;32m     15\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mstack([bt1,bt2,wv,mir,vis],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m300.0\u001b[39m)      \u001b[38;5;66;03m# Normalise\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Labels come from final frame in sequence\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(fp_seq[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 749. MiB for an array with shape (4, 3207, 3062, 5) and data type float32"
     ]
    }
   ],
   "source": [
    "from torch.amp import autocast\n",
    "\n",
    "# Training loop --------------------------------------------------------------\n",
    "best_acc = 0.0\n",
    "train_history, val_history = [], []\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    pbar = tqdm(range(len(train_seqs)//BATCH_SIZE), desc=f'Epoch {epoch}/{EPOCHS} [train]')\n",
    "    train_iter = iter(train_loader)\n",
    "    for _ in pbar:\n",
    "        Xb, yb = next(train_iter)\n",
    "        Xb = Xb.to(device, non_blocking=True)\n",
    "        yb = {k: v.to(device, non_blocking=True) for k,v in yb.items()}\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast('cuda'):\n",
    "            preds = model(Xb)\n",
    "            loss = compute_loss(preds, yb)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': train_loss/(_+1)})\n",
    "    train_loss /= len(pbar)\n",
    "    train_history.append(train_loss)\n",
    "\n",
    "    # Validation ------------------------------------------------------------\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_cloud, total_cloud = 0,0\n",
    "    with torch.no_grad():\n",
    "        pbar_val = tqdm(range(len(val_seqs)//BATCH_SIZE), desc=f'Epoch {epoch} [val]')\n",
    "        val_iter = iter(val_loader)\n",
    "        for _ in pbar_val:\n",
    "            Xb, yb = next(val_iter)\n",
    "            Xb = Xb.to(device, non_blocking=True)\n",
    "            yb = {k: v.to(device, non_blocking=True) for k,v in yb.items()}\n",
    "            with autocast(device_type='cuda'):\n",
    "                preds = model(Xb)\n",
    "                loss = compute_loss(preds, yb)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds_cloud = torch.sigmoid(preds['cloud'])>0.5\n",
    "            correct_cloud += (preds_cloud == yb['cloud'].bool()).sum().item()\n",
    "            total_cloud += yb['cloud'].numel()\n",
    "            pbar_val.set_postfix({'loss': val_loss/(_+1), 'cloud_acc': correct_cloud/total_cloud})\n",
    "    val_loss /= len(pbar_val)\n",
    "    val_history.append(val_loss)\n",
    "    cloud_acc = correct_cloud/total_cloud\n",
    "\n",
    "    # Save checkpoint -------------------------------------------------------\n",
    "    torch.save({'epoch':epoch,\n",
    "                'model_state_dict':model.state_dict(),\n",
    "                'optimizer_state_dict':optimizer.state_dict()},\n",
    "                os.path.join(MODEL_DIR, f\"model_epoch_{epoch:02d}.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af5a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Final Evaluation on validation set ----------------------------------------\n",
    "seg_keys = [\"cloud\",\"convective\",\"fog\"]\n",
    "reg_keys = [\"moisture\",\"thermo_contrast\",\"temp_trend\"]\n",
    "\n",
    "y_true_seg, y_pred_seg = {k:[] for k in seg_keys}, {k:[] for k in seg_keys}\n",
    "y_true_reg, y_pred_reg = {k:[] for k in reg_keys}, {k:[] for k in reg_keys}\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for Xb, yb in tqdm(val_loader, total=100, desc=\"Evaluation\"):  # limited batches for speed\n",
    "        Xb = Xb.to(device, non_blocking=True)\n",
    "        preds = model(Xb)\n",
    "        # collect predictions\n",
    "        for k in seg_keys:\n",
    "            y_true_seg[k].append(yb[k].flatten().cpu().numpy())\n",
    "            y_pred_seg[k].append(torch.sigmoid(preds[k]).flatten().cpu().numpy())\n",
    "        for k in reg_keys:\n",
    "            y_true_reg[k].append(yb[k].flatten().cpu().numpy())\n",
    "            y_pred_reg[k].append(preds[k].flatten().cpu().numpy())\n",
    "\n",
    "# Compute simple metrics\n",
    "for k in seg_keys:\n",
    "    yt = np.concatenate(y_true_seg[k])\n",
    "    yp = np.concatenate(y_pred_seg[k])>0.5\n",
    "    acc = accuracy_score(yt, yp)\n",
    "    print(f\"{k} accuracy: {acc:.3f}\")\n",
    "\n",
    "for k in reg_keys:\n",
    "    yt = np.concatenate(y_true_reg[k])\n",
    "    yp = np.concatenate(y_pred_reg[k])\n",
    "    mse_val = mean_squared_error(yt, yp)\n",
    "    print(f\"{k} MSE: {mse_val:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
