{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Space Debris Detection Pipeline (PySpark + TF/KerasCV + HDFS)\n",
        "\n",
        "This notebook implements an end-to-end pipeline for detecting space debris in images using:\n",
        "1.  **HDFS:** For storing image data and annotations.\n",
        "2.  **PySpark:** For reading and processing annotation metadata from HDFS.\n",
        "3.  **TensorFlow & KerasCV:** For building, training (on GPU), and evaluating a YOLOv8 object detection model using data read directly from HDFS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
            "Requirement already satisfied: findspark in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (2.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pandas in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: matplotlib in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (3.9.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from matplotlib) (6.5.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pyspark in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorflow in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (2.2.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (78.1.1)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (3.9.2)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow) (0.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (8.6.1)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting keras-cv\n",
            "  Using cached keras_cv-0.9.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from keras-cv) (25.0)\n",
            "Requirement already satisfied: absl-py in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from keras-cv) (2.2.2)\n",
            "Collecting regex (from keras-cv)\n",
            "  Using cached regex-2024.11.6-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
            "Collecting tensorflow-datasets (from keras-cv)\n",
            "  Using cached tensorflow_datasets-4.9.3-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting keras-core (from keras-cv)\n",
            "  Using cached keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting kagglehub (from keras-cv)\n",
            "  Using cached kagglehub-0.3.12-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting pyyaml (from kagglehub->keras-cv)\n",
            "  Using cached PyYAML-6.0.2-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: requests in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from kagglehub->keras-cv) (2.32.3)\n",
            "Collecting tqdm (from kagglehub->keras-cv)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from keras-core->keras-cv) (2.0.2)\n",
            "Requirement already satisfied: rich in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from keras-core->keras-cv) (14.0.0)\n",
            "Requirement already satisfied: namex in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from keras-core->keras-cv) (0.0.9)\n",
            "Requirement already satisfied: h5py in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from keras-core->keras-cv) (3.13.0)\n",
            "Collecting dm-tree (from keras-core->keras-cv)\n",
            "  Using cached dm_tree-0.1.8-cp39-cp39-win_amd64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from requests->kagglehub->keras-cv) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from requests->kagglehub->keras-cv) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from requests->kagglehub->keras-cv) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from requests->kagglehub->keras-cv) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from rich->keras-core->keras-cv) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from rich->keras-core->keras-cv) (2.19.1)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from rich->keras-core->keras-cv) (4.13.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-cv) (0.1.2)\n",
            "Collecting array-record (from tensorflow-datasets->keras-cv)\n",
            "  Using cached array_record-0.4.1-py39-none-any.whl.metadata (503 bytes)\n",
            "Collecting click (from tensorflow-datasets->keras-cv)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting etils>=0.9.0 (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv)\n",
            "  Using cached etils-1.5.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting promise (from tensorflow-datasets->keras-cv)\n",
            "  Using cached promise-2.3-py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.20 in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow-datasets->keras-cv) (5.29.4)\n",
            "Requirement already satisfied: psutil in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow-datasets->keras-cv) (7.0.0)\n",
            "Collecting tensorflow-metadata (from tensorflow-datasets->keras-cv)\n",
            "  Using cached tensorflow_metadata-1.17.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: termcolor in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow-datasets->keras-cv) (3.1.0)\n",
            "Collecting toml (from tensorflow-datasets->keras-cv)\n",
            "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: wrapt in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from tensorflow-datasets->keras-cv) (1.17.2)\n",
            "Collecting fsspec (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv)\n",
            "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: importlib_resources in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv) (6.5.2)\n",
            "Requirement already satisfied: zipp in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv) (3.21.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from click->tensorflow-datasets->keras-cv) (0.4.6)\n",
            "Requirement already satisfied: six in c:\\users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages (from promise->tensorflow-datasets->keras-cv) (1.17.0)\n",
            "Collecting protobuf>=3.20 (from tensorflow-datasets->keras-cv)\n",
            "  Using cached protobuf-4.21.12-cp39-cp39-win_amd64.whl.metadata (541 bytes)\n",
            "Using cached keras_cv-0.9.0-py3-none-any.whl (650 kB)\n",
            "Using cached kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
            "Using cached keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "Using cached dm_tree-0.1.8-cp39-cp39-win_amd64.whl (101 kB)\n",
            "Using cached PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
            "Using cached regex-2024.11.6-cp39-cp39-win_amd64.whl (274 kB)\n",
            "Using cached tensorflow_datasets-4.9.3-py3-none-any.whl (5.0 MB)\n",
            "Using cached etils-1.5.2-py3-none-any.whl (140 kB)\n",
            "Using cached array_record-0.4.1-py39-none-any.whl (3.0 MB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "Using cached tensorflow_metadata-1.17.1-py3-none-any.whl (31 kB)\n",
            "Using cached protobuf-4.21.12-cp39-cp39-win_amd64.whl (527 kB)\n",
            "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: dm-tree, tqdm, toml, regex, pyyaml, protobuf, promise, fsspec, etils, click, tensorflow-metadata, kagglehub, keras-core, array-record, tensorflow-datasets, keras-cv\n",
            "\n",
            "   -- -------------------------------------  1/16 [tqdm]\n",
            "   -- -------------------------------------  1/16 [tqdm]\n",
            "   -- -------------------------------------  1/16 [tqdm]\n",
            "   ------- --------------------------------  3/16 [regex]\n",
            "   ---------- -----------------------------  4/16 [pyyaml]\n",
            "   ---------- -----------------------------  4/16 [pyyaml]\n",
            "  Attempting uninstall: protobuf\n",
            "   ---------- -----------------------------  4/16 [pyyaml]\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "   ---------- -----------------------------  4/16 [pyyaml]\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "   ---------- -----------------------------  4/16 [pyyaml]\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "   ---------- -----------------------------  4/16 [pyyaml]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   ------------ ---------------------------  5/16 [protobuf]\n",
            "   --------------- ------------------------  6/16 [promise]\n",
            "   ----------------- ----------------------  7/16 [fsspec]\n",
            "   ----------------- ----------------------  7/16 [fsspec]\n",
            "   ----------------- ----------------------  7/16 [fsspec]\n",
            "   ----------------- ----------------------  7/16 [fsspec]\n",
            "   ----------------- ----------------------  7/16 [fsspec]\n",
            "   ----------------- ----------------------  7/16 [fsspec]\n",
            "   -------------------- -------------------  8/16 [etils]\n",
            "   -------------------- -------------------  8/16 [etils]\n",
            "   -------------------- -------------------  8/16 [etils]\n",
            "   -------------------- -------------------  8/16 [etils]\n",
            "   -------------------- -------------------  8/16 [etils]\n",
            "   -------------------- -------------------  8/16 [etils]\n",
            "   -------------------- -------------------  8/16 [etils]\n",
            "   ---------------------- -----------------  9/16 [click]\n",
            "   ---------------------- -----------------  9/16 [click]\n",
            "   ------------------------- -------------- 10/16 [tensorflow-metadata]\n",
            "   --------------------------- ------------ 11/16 [kagglehub]\n",
            "   --------------------------- ------------ 11/16 [kagglehub]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   ------------------------------ --------- 12/16 [keras-core]\n",
            "   -------------------------------- ------- 13/16 [array-record]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ----------------------------------- ---- 14/16 [tensorflow-datasets]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ------------------------------------- -- 15/16 [keras-cv]\n",
            "   ---------------------------------------- 16/16 [keras-cv]\n",
            "\n",
            "Successfully installed array-record-0.4.1 click-8.1.8 dm-tree-0.1.8 etils-1.5.2 fsspec-2025.3.2 kagglehub-0.3.12 keras-core-0.1.7 keras-cv-0.9.0 promise-2.3 protobuf-4.21.12 pyyaml-6.0.2 regex-2024.11.6 tensorflow-datasets-4.9.3 tensorflow-metadata-1.17.1 toml-0.10.2 tqdm-4.67.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\dhanu\\.conda\\envs\\tf_new_env\\Lib\\site-packages\\google\\~upb'.\n",
            "  You can safely remove it manually.\n",
            "c:\\Users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'resource'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Keras / KerasCV for the model\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Ensure Keras 3 is used if possible, otherwise adjust imports\u001b[39;00m\n\u001b[0;32m     33\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall keras-cv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bounding_box\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# from keras_cv import visualization # Removed/Commented out: May not exist in keras-cv 0.3.5 top-level\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# from tensorflow import keras # Use tf.keras usually\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages\\keras_cv\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Import everything from /api/ into keras.\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# Import * ignores names start with \"_\".\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Add everything in /api/ to the module search path.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages\\keras_cv\\api\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bounding_box\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callbacks\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m core\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages\\keras_cv\\api\\bounding_box\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbounding_box\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_format\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbounding_box\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensure_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ensure_tensor\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbounding_box\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CENTER_XYWH\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages\\keras_cv\\src\\__init__.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bounding_box  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callbacks  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datasets  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m losses  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages\\keras_cv\\src\\datasets\\__init__.py:14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The KerasCV Authors\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pascal_voc\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages\\keras_cv\\src\\datasets\\pascal_voc\\__init__.py:14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The KerasCV Authors\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpascal_voc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages\\keras_cv\\src\\datasets\\pascal_voc\\load.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The KerasCV Authors\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtfds\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bounding_box\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_cv_export\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages\\tensorflow_datasets\\__init__.py:43\u001b[0m\n\u001b[0;32m     41\u001b[0m _TIMESTAMP_IMPORT_STARTS \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mabsl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_tfds_logging\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m call_metadata \u001b[38;5;28;01mas\u001b[39;00m _call_metadata\n\u001b[0;32m     46\u001b[0m _metadata \u001b[38;5;241m=\u001b[39m _call_metadata\u001b[38;5;241m.\u001b[39mCallMetadata()\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages\\tensorflow_datasets\\core\\__init__.py:22\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Allow to use `tfds.core.Path` in dataset implementation which seems more\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# natural than having to import a third party module.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01metils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mepath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m community\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeamBasedBuilder\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BuilderConfig\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages\\tensorflow_datasets\\core\\community\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# coding=utf-8\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2023 The TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"Community dataset API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommunity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mock_builtin_to_use_gfile\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommunity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mock_huggingface_import\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommunity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder_cls_from_module\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages\\tensorflow_datasets\\core\\community\\huggingface_wrapper.py:31\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munittest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mock\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01metils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m epath\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataset_builder\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataset_info\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m download\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m reader_lib\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m registered\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m split_builder \u001b[38;5;28;01mas\u001b[39;00m split_builder_lib\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m splits \u001b[38;5;28;01mas\u001b[39;00m splits_lib\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_compat\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages\\tensorflow_datasets\\core\\split_builder.py:37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m splits \u001b[38;5;28;01mas\u001b[39;00m splits_lib\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m writer \u001b[38;5;28;01mas\u001b[39;00m writer_lib\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m shard_utils\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typing\u001b[38;5;241m.\u001b[39mTYPE_CHECKING:\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages\\tensorflow_datasets\\core\\writer.py:33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lazy_imports_lib\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m naming\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m shuffle\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m file_utils\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\tf_new_env\\lib\\site-packages\\tensorflow_datasets\\core\\shuffle.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mresource\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstruct\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Iterator, List, Optional\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'resource'"
          ]
        }
      ],
      "source": [
        "# Cell 1: Imports and Configuration\n",
        "\n",
        "# --- Protobuf Workaround ---\n",
        "# Set environment variable BEFORE importing tensorflow\n",
        "# to potentially avoid descriptor errors with certain protobuf/TF versions\n",
        "import os\n",
        "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
        "print(f\"Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\")\n",
        "\n",
        "# Core libraries\n",
        "%pip install findspark\n",
        "%pip install pandas\n",
        "%pip install matplotlib\n",
        "%pip install pyspark\n",
        "import findspark\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Ensure TensorFlow, Keras, and KerasCV are compatible\n",
        "%pip install tensorflow\n",
        "import tensorflow as tf # Now import tensorflow\n",
        "import subprocess # To run hdfs commands\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PySpark for data processing\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf, col, size\n",
        "from pyspark.sql.types import StringType, ArrayType, StructType, StructField, IntegerType, FloatType\n",
        "from pyspark import StorageLevel # Corrected Import! For persisting DataFrames if needed\n",
        "\n",
        "# Keras / KerasCV for the model\n",
        "# Ensure Keras 3 is used if possible, otherwise adjust imports\n",
        "%pip install keras-cv\n",
        "import keras_cv\n",
        "from keras_cv import bounding_box\n",
        "# from keras_cv import visualization # Removed/Commented out: May not exist in keras-cv 0.3.5 top-level\n",
        "# from tensorflow import keras # Use tf.keras usually\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam # Or other optimizers like AdamW\n",
        "\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "# Check if keras_cv is imported before accessing version\n",
        "if 'keras_cv' in locals() or 'keras_cv' in globals():\n",
        "    # Attempt to get version, handle potential AttributeError if __version__ doesn't exist\n",
        "    try:\n",
        "        print(f\"KerasCV Version: {keras_cv.__version__}\")\n",
        "    except AttributeError:\n",
        "        print(\"KerasCV Version: Not available (likely older version)\")\n",
        "else:\n",
        "    print(\"KerasCV not imported (likely due to previous error). Please ensure it's installed.\")\n",
        "\n",
        "\n",
        "# --- Configuration ---\n",
        "# HDFS Configuration (!! MODIFY IF NEEDED !!)\n",
        "HDFS_NAMENODE = \"hdfs://localhost:9000\"\n",
        "HDFS_USER = os.getenv(\"HADOOP_USER_NAME\", \"dhanu\") # Use system env var or default to 'dhanu'\n",
        "HDFS_BASE_DIR_NAME = \"debris_detection\"\n",
        "HDFS_BASE_PATH = f\"{HDFS_NAMENODE}/user/{HDFS_USER}/{HDFS_BASE_DIR_NAME}\"\n",
        "\n",
        "# Local Paths (Ensure these are correct based on your 'debris-detection' folder location)\n",
        "# Assuming your notebook is running from a directory *outside* 'debris-detection'\n",
        "LOCAL_BASE_DIR = r\"C:\\college\\CV\\COSMOS\\debris-detection\" # Main project folder\n",
        "LOCAL_TRAIN_IMG_DIR = os.path.join(LOCAL_BASE_DIR, \"train\")\n",
        "LOCAL_VAL_IMG_DIR = os.path.join(LOCAL_BASE_DIR, \"val\")\n",
        "LOCAL_TEST_IMG_DIR = os.path.join(LOCAL_BASE_DIR, \"test\")\n",
        "LOCAL_TRAIN_CSV = os.path.join(LOCAL_BASE_DIR, \"train.csv\")\n",
        "LOCAL_VAL_CSV = os.path.join(LOCAL_BASE_DIR, \"val.csv\")\n",
        "\n",
        "# Define HDFS target paths\n",
        "HDFS_TRAIN_IMG_DIR = f\"{HDFS_BASE_PATH}/train_images\"\n",
        "HDFS_VAL_IMG_DIR = f\"{HDFS_BASE_PATH}/val_images\"\n",
        "HDFS_TEST_IMG_DIR = f\"{HDFS_BASE_PATH}/test_images\"\n",
        "HDFS_ANNOTATIONS_DIR = f\"{HDFS_BASE_PATH}/annotations\"\n",
        "HDFS_TRAIN_CSV_PATH = f\"{HDFS_ANNOTATIONS_DIR}/train.csv\"\n",
        "HDFS_VAL_CSV_PATH = f\"{HDFS_ANNOTATIONS_DIR}/val.csv\"\n",
        "\n",
        "# Define Model Save Path (Local directory for checkpoints)\n",
        "MODEL_SAVE_DIR = os.path.join(LOCAL_BASE_DIR, \"debris_yolov8_checkpoints\")\n",
        "os.makedirs(MODEL_SAVE_DIR, exist_ok=True) # Ensure the directory exists\n",
        "\n",
        "# TF Data Pipeline & Model Parameters\n",
        "IMG_HEIGHT = 640 # YOLOv8 often uses 640x640\n",
        "IMG_WIDTH = 640\n",
        "BATCH_SIZE = 4   # Start small with YOLOv8, increase if GPU memory allows (e.g., 8, 16)\n",
        "BUFFER_SIZE = 1000 # For shuffling tf.data dataset\n",
        "# Define class mapping - adjust if you have more classes later\n",
        "CLASS_MAPPING = {0: \"debris\"} # Class ID 0 maps to 'debris'\n",
        "NUM_CLASSES = len(CLASS_MAPPING)\n",
        "# Bounding box format used by KerasCV YOLOv8 preset\n",
        "# We will convert our source [xmin, xmax, ymin, ymax] to this\n",
        "TARGET_BBOX_FORMAT = \"xyxy\" # [xmin, ymin, xmax, ymax] relative coordinates\n",
        "\n",
        "# --- Spark Initialization ---\n",
        "print(\"Initializing Spark Session...\")\n",
        "try:\n",
        "    findspark.init() # Finds Spark installation\n",
        "    # Corrected Indentation:\n",
        "    spark = SparkSession.builder \\\n",
        "        .appName(\"DebrisDetectionHDFS_YOLO\") \\\n",
        "        .config(\"spark.executor.memory\", \"4g\") \\\n",
        "        .config(\"spark.driver.memory\", \"2g\") \\\n",
        "        .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
        "        .getOrCreate() # Add other necessary Spark/Hadoop configs if needed\n",
        "\n",
        "    sc = spark.sparkContext\n",
        "    print(\"SparkSession Initialized Successfully.\")\n",
        "    # Check if Spark UI URL is available\n",
        "    try:\n",
        "        print(f\"Spark UI: {sc.uiWebUrl}\") # Useful for monitoring Spark jobs\n",
        "    except AttributeError:\n",
        "        print(\"Spark UI URL not available.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing Spark: {e}\")\n",
        "    print(\"Please ensure Spark is correctly installed and configured.\")\n",
        "    raise\n",
        "\n",
        "# --- GPU Check ---\n",
        "print(\"\\nChecking for GPU...\")\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Set memory growth to avoid allocating all memory at once\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs available. Using GPU for training.\")\n",
        "  except RuntimeError as e:\n",
        "    print(f\"GPU Error: {e}. Training might fall back to CPU.\")\n",
        "else:\n",
        "    print(\"No GPU detected by TensorFlow. Training will run on CPU.\")\n",
        "\n",
        "print(\"-\" * 30)\n",
        "print(\"Configuration Summary:\")\n",
        "print(f\"  HDFS Base Path: {HDFS_BASE_PATH}\")\n",
        "print(f\"  Local Base Dir: {LOCAL_BASE_DIR}\")\n",
        "print(f\"  Model Save Dir: {MODEL_SAVE_DIR}\")\n",
        "print(f\"  Image Size: ({IMG_HEIGHT}, {IMG_WIDTH})\")\n",
        "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"  Target BBox Format: {TARGET_BBOX_FORMAT}\")\n",
        "print(f\"  Number of Classes: {NUM_CLASSES}\")\n",
        "print(\"-\" * 30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2: Copy Local Data to HDFS\n",
        "\n",
        "**Run this cell only ONCE** to copy your image folders and CSV files from your local disk into HDFS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting data copy to HDFS...\n",
            "This may take some time depending on data size and network speed.\n",
            "\n",
            "Creating HDFS directories...\n",
            "Running HDFS command: hdfs dfs -mkdir -p hdfs://localhost:9000/user/dhanu/debris_detection\n",
            "STDOUT:\n",
            " \n",
            "STDERR:\n",
            " mkdir: RPC response has invalid length of -16777216\n",
            "\n",
            "Command successful.\n",
            "Running HDFS command: hdfs dfs -mkdir -p hdfs://localhost:9000/user/dhanu/debris_detection/train_images\n",
            "STDOUT:\n",
            " \n",
            "STDERR:\n",
            " mkdir: RPC response has invalid length of -16777216\n",
            "\n",
            "Command successful.\n",
            "Running HDFS command: hdfs dfs -mkdir -p hdfs://localhost:9000/user/dhanu/debris_detection/val_images\n",
            "STDOUT:\n",
            " \n",
            "STDERR:\n",
            " mkdir: RPC response has invalid length of -16777216\n",
            "\n",
            "Command successful.\n",
            "Running HDFS command: hdfs dfs -mkdir -p hdfs://localhost:9000/user/dhanu/debris_detection/test_images\n",
            "STDOUT:\n",
            " \n",
            "STDERR:\n",
            " mkdir: RPC response has invalid length of -16777216\n",
            "\n",
            "Command successful.\n",
            "Running HDFS command: hdfs dfs -mkdir -p hdfs://localhost:9000/user/dhanu/debris_detection/annotations\n",
            "STDOUT:\n",
            " \n",
            "STDERR:\n",
            " mkdir: RPC response has invalid length of -16777216\n",
            "\n",
            "Command successful.\n",
            "\n",
            "Copying training images...\n",
            "Running HDFS command: hdfs dfs -put -f C:\\college\\CV\\COSMOS\\debris-detection\\train hdfs://localhost:9000/user/dhanu/debris_detection/train_images\n",
            "STDOUT:\n",
            " \n",
            "STDERR:\n",
            " put: RPC response has invalid length of -16777216\n",
            "\n",
            "Command successful.\n",
            "\n",
            "Copying validation images...\n",
            "Running HDFS command: hdfs dfs -put -f C:\\college\\CV\\COSMOS\\debris-detection\\val hdfs://localhost:9000/user/dhanu/debris_detection/val_images\n",
            "STDOUT:\n",
            " \n",
            "STDERR:\n",
            " put: RPC response has invalid length of -16777216\n",
            "\n",
            "Command successful.\n",
            "\n",
            "Copying test images...\n",
            "Running HDFS command: hdfs dfs -put -f C:\\college\\CV\\COSMOS\\debris-detection\\test hdfs://localhost:9000/user/dhanu/debris_detection/test_images\n",
            "STDOUT:\n",
            " \n",
            "STDERR:\n",
            " put: RPC response has invalid length of -16777216\n",
            "\n",
            "Command successful.\n",
            "\n",
            "Copying training CSV...\n",
            "Running HDFS command: hdfs dfs -put -f C:\\college\\CV\\COSMOS\\debris-detection\\train.csv hdfs://localhost:9000/user/dhanu/debris_detection/annotations/train.csv\n",
            "STDOUT:\n",
            " \n",
            "STDERR:\n",
            " put: RPC response has invalid length of -16777216\n",
            "\n",
            "Command successful.\n",
            "\n",
            "Copying validation CSV...\n",
            "Running HDFS command: hdfs dfs -put -f C:\\college\\CV\\COSMOS\\debris-detection\\val.csv hdfs://localhost:9000/user/dhanu/debris_detection/annotations/val.csv\n",
            "STDOUT:\n",
            " \n",
            "STDERR:\n",
            " put: RPC response has invalid length of -16777216\n",
            "\n",
            "Command successful.\n",
            "\n",
            "--- Data Copy to HDFS Initiated ---\n",
            "Verify the contents in HDFS using commands like:\n",
            "  hdfs dfs -ls hdfs://localhost:9000/user/dhanu/debris_detection\n",
            "  hdfs dfs -ls hdfs://localhost:9000/user/dhanu/debris_detection/train_images\n",
            "  hdfs dfs -ls hdfs://localhost:9000/user/dhanu/debris_detection/annotations\n",
            "------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Copy Local Data to HDFS (Run this cell only ONCE)\n",
        "\n",
        "# Function to run HDFS commands more robustly\n",
        "def run_hdfs_command(command_parts):\n",
        "    \"\"\"Runs an HDFS command using subprocess and prints output/errors.\"\"\"\n",
        "    # Ensure HADOOP_HOME/bin is in PATH or provide full path to hdfs executable if needed\n",
        "    full_command = [\"hdfs\", \"dfs\"] + command_parts\n",
        "    print(f\"Running HDFS command: {' '.join(full_command)}\")\n",
        "    try:\n",
        "        # Using shell=True might be necessary on Windows for complex paths or wildcards\n",
        "        # Ensure paths with spaces are handled correctly if they occur\n",
        "        process = subprocess.run(full_command, check=True, capture_output=True, text=True, shell=True)\n",
        "        print(\"STDOUT:\\n\", process.stdout)\n",
        "        if process.stderr:\n",
        "            print(\"STDERR:\\n\", process.stderr) # Print stderr even on success, might contain warnings\n",
        "        print(\"Command successful.\")\n",
        "        return True\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error running command: {' '.join(full_command)}\")\n",
        "        print(\"Return code:\", e.returncode)\n",
        "        print(\"STDERR:\\n\", e.stderr)\n",
        "        print(\"STDOUT:\\n\", e.stdout)\n",
        "        return False\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: 'hdfs' command not found. Make sure Hadoop bin directory is in your system PATH.\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return False\n",
        "\n",
        "print(\"Starting data copy to HDFS...\")\n",
        "print(\"This may take some time depending on data size and network speed.\")\n",
        "\n",
        "# 1. Create base directories in HDFS (use -p for idempotency)\n",
        "print(\"\\nCreating HDFS directories...\")\n",
        "run_hdfs_command([\"-mkdir\", \"-p\", HDFS_BASE_PATH])\n",
        "run_hdfs_command([\"-mkdir\", \"-p\", HDFS_TRAIN_IMG_DIR])\n",
        "run_hdfs_command([\"-mkdir\", \"-p\", HDFS_VAL_IMG_DIR])\n",
        "run_hdfs_command([\"-mkdir\", \"-p\", HDFS_TEST_IMG_DIR])\n",
        "run_hdfs_command([\"-mkdir\", \"-p\", HDFS_ANNOTATIONS_DIR])\n",
        "\n",
        "# 2. Copy Image Directories\n",
        "# Use '-put -f'. '-f' overwrites if destination exists.\n",
        "# Putting the directory itself copies the directory *into* the destination.\n",
        "print(\"\\nCopying training images...\")\n",
        "# This will create .../debris_detection/train_images/train\n",
        "run_hdfs_command([\"-put\", \"-f\", LOCAL_TRAIN_IMG_DIR, HDFS_TRAIN_IMG_DIR])\n",
        "\n",
        "print(\"\\nCopying validation images...\")\n",
        "# This will create .../debris_detection/val_images/val\n",
        "run_hdfs_command([\"-put\", \"-f\", LOCAL_VAL_IMG_DIR, HDFS_VAL_IMG_DIR])\n",
        "\n",
        "print(\"\\nCopying test images...\")\n",
        "# This will create .../debris_detection/test_images/test\n",
        "run_hdfs_command([\"-put\", \"-f\", LOCAL_TEST_IMG_DIR, HDFS_TEST_IMG_DIR])\n",
        "\n",
        "# 3. Copy CSV Files\n",
        "print(\"\\nCopying training CSV...\")\n",
        "run_hdfs_command([\"-put\", \"-f\", LOCAL_TRAIN_CSV, HDFS_TRAIN_CSV_PATH])\n",
        "\n",
        "print(\"\\nCopying validation CSV...\")\n",
        "run_hdfs_command([\"-put\", \"-f\", LOCAL_VAL_CSV, HDFS_VAL_CSV_PATH])\n",
        "\n",
        "print(\"\\n--- Data Copy to HDFS Initiated ---\")\n",
        "print(\"Verify the contents in HDFS using commands like:\")\n",
        "print(f\"  hdfs dfs -ls {HDFS_BASE_PATH}\")\n",
        "print(f\"  hdfs dfs -ls {HDFS_TRAIN_IMG_DIR}\") # Should show 'train' folder inside\n",
        "print(f\"  hdfs dfs -ls {HDFS_ANNOTATIONS_DIR}\") # Should show csv files\n",
        "print(\"------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 3: Load and Process Annotations using PySpark\n",
        "\n",
        "Read the annotation CSV files from HDFS, parse the bounding box strings, and generate the full HDFS paths for each image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and processing annotations from HDFS using PySpark...\n",
            "Reading training annotations from: hdfs://localhost:9000/user/dhanu/debris_detection/annotations/train.csv\n",
            "Error reading HDFS file hdfs://localhost:9000/user/dhanu/debris_detection/annotations/train.csv: An error occurred while calling o51.csv.\n",
            ": java.io.IOException: Failed on local exception: com.google.protobuf.InvalidProtocolBufferException: Message missing required fields: callId, status; Host Details : local host is: \"Stabl3/192.168.1.3\"; destination host is: \"localhost\":9000; \n",
            "\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:776)\n",
            "\tat org.apache.hadoop.ipc.Client.call(Client.java:1480)\n",
            "\tat org.apache.hadoop.ipc.Client.call(Client.java:1413)\n",
            "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
            "\tat com.sun.proxy.$Proxy20.getFileInfo(Unknown Source)\n",
            "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:776)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
            "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
            "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
            "\tat com.sun.proxy.$Proxy21.getFileInfo(Unknown Source)\n",
            "\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:2108)\n",
            "\tat org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1305)\n",
            "\tat org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)\n",
            "\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n",
            "\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1317)\n",
            "\tat org.apache.hadoop.fs.FileSystem.isDirectory(FileSystem.java:1439)\n",
            "\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:47)\n",
            "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)\n",
            "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:297)\n",
            "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:286)\n",
            "\tat scala.Option.getOrElse(Option.scala:189)\n",
            "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:286)\n",
            "\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:723)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
            "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
            "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
            "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
            "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
            "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
            "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
            "\tat java.lang.Thread.run(Thread.java:748)\n",
            "Caused by: com.google.protobuf.InvalidProtocolBufferException: Message missing required fields: callId, status\n",
            "\tat com.google.protobuf.UninitializedMessageException.asInvalidProtocolBufferException(UninitializedMessageException.java:81)\n",
            "\tat com.google.protobuf.AbstractParser.checkMessageInitialized(AbstractParser.java:71)\n",
            "\tat com.google.protobuf.AbstractParser.parseDelimitedFrom(AbstractParser.java:253)\n",
            "\tat com.google.protobuf.AbstractParser.parseDelimitedFrom(AbstractParser.java:259)\n",
            "\tat com.google.protobuf.AbstractParser.parseDelimitedFrom(AbstractParser.java:49)\n",
            "\tat org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto.parseDelimitedFrom(RpcHeaderProtos.java:3167)\n",
            "\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1087)\n",
            "\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:980)\n",
            "\n",
            "Please ensure the file exists, has correct permissions, schema, and Spark config is right.\n"
          ]
        },
        {
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling o51.csv.\n: java.io.IOException: Failed on local exception: com.google.protobuf.InvalidProtocolBufferException: Message missing required fields: callId, status; Host Details : local host is: \"Stabl3/192.168.1.3\"; destination host is: \"localhost\":9000; \r\n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:776)\r\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1480)\r\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1413)\r\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\r\n\tat com.sun.proxy.$Proxy20.getFileInfo(Unknown Source)\r\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:776)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\r\n\tat com.sun.proxy.$Proxy21.getFileInfo(Unknown Source)\r\n\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:2108)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1305)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)\r\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1317)\r\n\tat org.apache.hadoop.fs.FileSystem.isDirectory(FileSystem.java:1439)\r\n\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:47)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:297)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:286)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:286)\r\n\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:723)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: com.google.protobuf.InvalidProtocolBufferException: Message missing required fields: callId, status\r\n\tat com.google.protobuf.UninitializedMessageException.asInvalidProtocolBufferException(UninitializedMessageException.java:81)\r\n\tat com.google.protobuf.AbstractParser.checkMessageInitialized(AbstractParser.java:71)\r\n\tat com.google.protobuf.AbstractParser.parseDelimitedFrom(AbstractParser.java:253)\r\n\tat com.google.protobuf.AbstractParser.parseDelimitedFrom(AbstractParser.java:259)\r\n\tat com.google.protobuf.AbstractParser.parseDelimitedFrom(AbstractParser.java:49)\r\n\tat org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto.parseDelimitedFrom(RpcHeaderProtos.java:3167)\r\n\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1087)\r\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:980)\r\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading training annotations from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHDFS_TRAIN_CSV_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 15\u001b[0m     train_annotations_df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHDFS_TRAIN_CSV_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully read training CSV. Count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_annotations_df\u001b[38;5;241m.\u001b[39mcount()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# Add count action\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\w\\lib\\site-packages\\pyspark\\sql\\readwriter.py:535\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[1;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup)\u001b[0m\n\u001b[0;32m    533\u001b[0m     path \u001b[38;5;241m=\u001b[39m [path]\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator):\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\w\\lib\\site-packages\\py4j\\java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\w\\lib\\site-packages\\pyspark\\sql\\utils.py:128\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    130\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
            "File \u001b[1;32mc:\\Users\\dhanu\\.conda\\envs\\w\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
            "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o51.csv.\n: java.io.IOException: Failed on local exception: com.google.protobuf.InvalidProtocolBufferException: Message missing required fields: callId, status; Host Details : local host is: \"Stabl3/192.168.1.3\"; destination host is: \"localhost\":9000; \r\n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:776)\r\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1480)\r\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1413)\r\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\r\n\tat com.sun.proxy.$Proxy20.getFileInfo(Unknown Source)\r\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:776)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\r\n\tat com.sun.proxy.$Proxy21.getFileInfo(Unknown Source)\r\n\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:2108)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1305)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)\r\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1317)\r\n\tat org.apache.hadoop.fs.FileSystem.isDirectory(FileSystem.java:1439)\r\n\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:47)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:297)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:286)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:286)\r\n\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:723)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: com.google.protobuf.InvalidProtocolBufferException: Message missing required fields: callId, status\r\n\tat com.google.protobuf.UninitializedMessageException.asInvalidProtocolBufferException(UninitializedMessageException.java:81)\r\n\tat com.google.protobuf.AbstractParser.checkMessageInitialized(AbstractParser.java:71)\r\n\tat com.google.protobuf.AbstractParser.parseDelimitedFrom(AbstractParser.java:253)\r\n\tat com.google.protobuf.AbstractParser.parseDelimitedFrom(AbstractParser.java:259)\r\n\tat com.google.protobuf.AbstractParser.parseDelimitedFrom(AbstractParser.java:49)\r\n\tat org.apache.hadoop.ipc.protobuf.RpcHeaderProtos$RpcResponseHeaderProto.parseDelimitedFrom(RpcHeaderProtos.java:3167)\r\n\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1087)\r\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:980)\r\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Load and Process Annotations using PySpark\n",
        "\n",
        "print(\"Loading and processing annotations from HDFS using PySpark...\")\n",
        "\n",
        "# --- Define Schema for the CSV ---\n",
        "# Based on train.pdf, columns are 'ImageID' and 'bboxes'\n",
        "schema = StructType([\n",
        "    StructField(\"ImageID\", StringType(), True),\n",
        "    StructField(\"bboxes\", StringType(), True)   # Read bboxes as string first\n",
        "])\n",
        "\n",
        "# --- Read the training CSV from HDFS ---\n",
        "print(f\"Reading training annotations from: {HDFS_TRAIN_CSV_PATH}\")\n",
        "try:\n",
        "    train_annotations_df = spark.read.csv(HDFS_TRAIN_CSV_PATH, header=True, schema=schema)\n",
        "    print(f\"Successfully read training CSV. Count: {train_annotations_df.count()}\") # Add count action\n",
        "except Exception as e:\n",
        "    print(f\"Error reading HDFS file {HDFS_TRAIN_CSV_PATH}: {e}\")\n",
        "    print(\"Please ensure the file exists, has correct permissions, schema, and Spark config is right.\")\n",
        "    raise\n",
        "\n",
        "# --- Define a UDF to parse the bounding box string ---\n",
        "# Source format seems to be [xmin, xmax, ymin, ymax]\n",
        "# Target format for KerasCV YOLO is usually \"xyxy\": [xmin, ymin, xmax, ymax]\n",
        "# We will store the parsed values in the target format directly.\n",
        "bbox_struct_schema = StructType([\n",
        "    StructField(\"xmin\", IntegerType(), False),\n",
        "    StructField(\"ymin\", IntegerType(), False),\n",
        "    StructField(\"xmax\", IntegerType(), False),\n",
        "    StructField(\"ymax\", IntegerType(), False)\n",
        "])\n",
        "bbox_array_schema = ArrayType(bbox_struct_schema)\n",
        "\n",
        "def parse_bboxes_to_xyxy(bbox_str):\n",
        "    \"\"\"Parses the bounding box string and converts to xyxy format.\"\"\"\n",
        "    if bbox_str is None or not bbox_str.strip():\n",
        "        return []\n",
        "    try:\n",
        "        raw_list = json.loads(bbox_str.replace(\"'\", '\"'))\n",
        "        parsed_list = []\n",
        "        for box in raw_list:\n",
        "            if isinstance(box, list) and len(box) == 4:\n",
        "                try:\n",
        "                    # Original format: [xmin, xmax, ymin, ymax]\n",
        "                    # Target format:   [xmin, ymin, xmax, ymax]\n",
        "                    parsed_list.append({\n",
        "                        \"xmin\": int(box[0]), \"ymin\": int(box[2]),\n",
        "                        \"xmax\": int(box[1]), \"ymax\": int(box[3])\n",
        "                    })\n",
        "                except (ValueError, TypeError):\n",
        "                    print(f\"Warning: Skipping invalid numeric data in box: {box} from string: {bbox_str}\")\n",
        "                    continue # Skip invalid box\n",
        "            else:\n",
        "                 print(f\"Warning: Skipping invalid box format: {box} from string: {bbox_str}\")\n",
        "        return parsed_list\n",
        "    except (json.JSONDecodeError, TypeError) as e:\n",
        "        print(f\"Error parsing bbox string: '{bbox_str}', Error: {e}\")\n",
        "        return [] # Return empty list on error\n",
        "\n",
        "parse_bboxes_udf = udf(parse_bboxes_to_xyxy, bbox_array_schema)\n",
        "\n",
        "# --- Apply the UDF ---\n",
        "train_annotations_df = train_annotations_df.withColumn(\"bboxes_parsed\", parse_bboxes_udf(col(\"bboxes\"))) \\\n",
        "                                           .drop(\"bboxes\") # Drop the original string column\n",
        "\n",
        "# --- Construct Full HDFS Image Paths ---\n",
        "# Path structure after copy: HDFS_TRAIN_IMG_DIR/train/<ImageID>.jpg\n",
        "train_img_folder_name = os.path.basename(LOCAL_TRAIN_IMG_DIR) # e.g., 'train'\n",
        "print(f\"Constructing HDFS paths assuming images are in folder: {train_img_folder_name}\")\n",
        "\n",
        "add_hdfs_path_udf = udf(\n",
        "    lambda image_id: f\"{HDFS_TRAIN_IMG_DIR}/{train_img_folder_name}/{image_id}.jpg\",\n",
        "    StringType()\n",
        ")\n",
        "\n",
        "train_df = train_annotations_df.withColumn(\"image_path\", add_hdfs_path_udf(col(\"ImageID\")))\n",
        "\n",
        "# Filter out rows where parsing might have failed or path is invalid\n",
        "train_df = train_df.filter(col(\"image_path\").isNotNull())\n",
        "# Keep only images that have at least one valid bounding box after parsing\n",
        "train_df = train_df.filter(size(col(\"bboxes_parsed\")) > 0)\n",
        "\n",
        "# --- Show results ---\n",
        "print(\"\\nProcessed Training Annotations Schema:\")\n",
        "train_df.printSchema()\n",
        "print(\"\\nSample Processed Training Data (showing 5 rows):\")\n",
        "train_df.show(5, truncate=50, vertical=True) # Use vertical for better display of nested data\n",
        "\n",
        "# --- Repeat for Validation Data ---\n",
        "print(f\"\\nReading validation annotations from: {HDFS_VAL_CSV_PATH}\")\n",
        "try:\n",
        "    val_annotations_df = spark.read.csv(HDFS_VAL_CSV_PATH, header=True, schema=schema)\n",
        "    print(f\"Successfully read validation CSV. Count: {val_annotations_df.count()}\")\n",
        "\n",
        "    val_annotations_df = val_annotations_df.withColumn(\"bboxes_parsed\", parse_bboxes_udf(col(\"bboxes\"))) \\\n",
        "                                            .drop(\"bboxes\")\n",
        "\n",
        "    val_img_folder_name = os.path.basename(LOCAL_VAL_IMG_DIR) # e.g., 'val'\n",
        "    print(f\"Constructing HDFS paths assuming validation images are in folder: {val_img_folder_name}\")\n",
        "    add_val_hdfs_path_udf = udf(\n",
        "        lambda image_id: f\"{HDFS_VAL_IMG_DIR}/{val_img_folder_name}/{image_id}.jpg\",\n",
        "        StringType()\n",
        "    )\n",
        "    val_df = val_annotations_df.withColumn(\"image_path\", add_val_hdfs_path_udf(col(\"ImageID\")))\n",
        "    val_df = val_df.filter(col(\"image_path\").isNotNull())\n",
        "    val_df = val_df.filter(size(col(\"bboxes_parsed\")) > 0) # Keep only images with boxes\n",
        "\n",
        "    print(\"\\nProcessed Validation Annotations Schema:\")\n",
        "    val_df.printSchema()\n",
        "    print(\"\\nSample Processed Validation Data (showing 5 rows):\")\n",
        "    val_df.show(5, truncate=50, vertical=True)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error processing validation data from HDFS: {e}\")\n",
        "    val_df = None # Set to None if validation data fails to load\n",
        "\n",
        "print(\"\\nSpark processing finished.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4: Prepare TensorFlow Datasets (`tf.data`)\n",
        "\n",
        "Collect the processed data from Spark DataFrames into Pandas DataFrames (on the driver node) and then create efficient `tf.data` pipelines to load images from HDFS and prepare data for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Prepare TensorFlow Datasets (tf.data)\n",
        "\n",
        "print(\"Preparing TensorFlow datasets from Spark data...\")\n",
        "\n",
        "# --- Collect data to the driver node (Pandas DataFrame) ---\n",
        "# Acceptable for ~1.2GB total data on a 16GB RAM machine, but monitor memory usage.\n",
        "print(\"Collecting Spark DataFrame data to Pandas DataFrame on the driver...\")\n",
        "try:\n",
        "    # Select only the necessary columns\n",
        "    train_data_pd = train_df.select(\"image_path\", \"bboxes_parsed\").toPandas()\n",
        "    print(f\"Collected {len(train_data_pd)} training samples.\")\n",
        "    if val_df is not None:\n",
        "        val_data_pd = val_df.select(\"image_path\", \"bboxes_parsed\").toPandas()\n",
        "        print(f\"Collected {len(val_data_pd)} validation samples.\")\n",
        "    else:\n",
        "        val_data_pd = pd.DataFrame(columns=['image_path', 'bboxes_parsed']) # Empty df if no val data\n",
        "        print(\"Validation data was not loaded successfully from Spark.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error collecting data to driver: {e}\")\n",
        "    print(\"This might happen if the dataset is too large for driver memory or due to Arrow issues.\")\n",
        "    raise\n",
        "\n",
        "# --- Define the function to load and preprocess images and labels ---\n",
        "# This function will be wrapped in tf.py_function\n",
        "def load_and_preprocess_for_tf(image_path_str, bboxes_list_of_dicts):\n",
        "    \"\"\"Loads image from HDFS, preprocesses, and formats boxes/labels for KerasCV.\"\"\"\n",
        "    # 1. Load Image from HDFS\n",
        "    try:\n",
        "        img_bytes = tf.io.read_file(image_path_str)\n",
        "        img = tf.image.decode_jpeg(img_bytes, channels=3)\n",
        "        img_shape = tf.shape(img, out_type=tf.float32) # Use float for division\n",
        "        original_height, original_width = img_shape[0], img_shape[1]\n",
        "    except Exception as e:\n",
        "        # Handle potential errors during file reading/decoding\n",
        "        tf.print(f\"Error loading image {image_path_str}: {e}\")\n",
        "        # Return empty/dummy data consistent with expected output structure\n",
        "        img = tf.zeros([IMG_HEIGHT, IMG_WIDTH, 3], dtype=tf.float32)\n",
        "        boxes_xyxy_rel = tf.zeros([0, 4], dtype=tf.float32) # No boxes\n",
        "        class_ids = tf.zeros([0], dtype=tf.int64) # No labels\n",
        "        return img, boxes_xyxy_rel, class_ids\n",
        "\n",
        "    # 2. Preprocess Image (Resize only, normalization often done by model layers)\n",
        "    img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH], method='bilinear') # Use bilinear or nearest\n",
        "    img = tf.cast(img, dtype=tf.float32) # Ensure float32 type\n",
        "\n",
        "    # 3. Process Bounding Boxes\n",
        "    num_boxes = len(bboxes_list_of_dicts)\n",
        "    boxes_xyxy_abs = np.zeros((num_boxes, 4), dtype=np.float32)\n",
        "    class_ids = np.zeros((num_boxes,), dtype=np.int64)\n",
        "\n",
        "    if num_boxes > 0:\n",
        "        for i, box_dict in enumerate(bboxes_list_of_dicts):\n",
        "            # Already in xyxy format from Spark UDF\n",
        "            boxes_xyxy_abs[i, 0] = box_dict['xmin']\n",
        "            boxes_xyxy_abs[i, 1] = box_dict['ymin']\n",
        "            boxes_xyxy_abs[i, 2] = box_dict['xmax']\n",
        "            boxes_xyxy_abs[i, 3] = box_dict['ymax']\n",
        "            # Assign class ID (assuming single class 'debris' with ID 0)\n",
        "            class_ids[i] = 0 # Corresponds to CLASS_MAPPING\n",
        "\n",
        "        # Convert absolute pixel coordinates to relative [0, 1] coordinates\n",
        "        # Ensure division by non-zero dimensions\n",
        "        divisor = np.array([original_width, original_height, original_width, original_height], dtype=np.float32)\n",
        "        divisor = np.maximum(divisor, 1.0) # Avoid division by zero if image dimensions are somehow 0\n",
        "        boxes_xyxy_rel = boxes_xyxy_abs / divisor\n",
        "\n",
        "        # Clip boxes to [0, 1] range to handle potential rounding errors or boxes slightly outside\n",
        "        boxes_xyxy_rel = np.clip(boxes_xyxy_rel, 0.0, 1.0)\n",
        "\n",
        "        # Convert to TF tensors\n",
        "        boxes_tensor = tf.convert_to_tensor(boxes_xyxy_rel, dtype=tf.float32)\n",
        "        labels_tensor = tf.convert_to_tensor(class_ids, dtype=tf.int64)\n",
        "\n",
        "    else: # Handle images with no bounding boxes\n",
        "        boxes_tensor = tf.zeros((0, 4), dtype=tf.float32)\n",
        "        labels_tensor = tf.zeros((0,), dtype=tf.int64)\n",
        "\n",
        "\n",
        "    # 4. Format Output for KerasCV model.fit()\n",
        "    # KerasCV models typically expect a dictionary with 'images' and 'bounding_boxes' keys\n",
        "    # The 'bounding_boxes' value is another dictionary containing 'boxes' and 'classes'.\n",
        "    # Note: During inference/prediction, only 'images' are needed.\n",
        "    # We return image, boxes, classes separately here and combine them later in the pipeline.\n",
        "    return img, boxes_tensor, labels_tensor\n",
        "\n",
        "\n",
        "# --- Create the tf.data Datasets using tf.py_function ---\n",
        "def create_tf_dataset(pandas_df):\n",
        "    \"\"\"Creates a tf.data.Dataset from the collected Pandas data.\"\"\"\n",
        "    # Create a dataset of image paths and the list of bbox dictionaries\n",
        "    # Ensure 'bboxes_parsed' is treated as object dtype for lists/dicts\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((\n",
        "        pandas_df['image_path'].tolist(),\n",
        "        tf.ragged.constant(pandas_df['bboxes_parsed'].tolist(), dtype=tf.string) # Temporarily use ragged string to pass structure\n",
        "    ))\n",
        "\n",
        "    # Define the parsing function within the TF graph context if possible,\n",
        "    # otherwise use py_function carefully.\n",
        "    def parse_and_process(img_path, bboxes_ragged_str):\n",
        "        # This part runs inside tf.py_function, needs careful handling of types\n",
        "        # Decode the ragged string tensor back to list of dicts (might be complex)\n",
        "        # A simpler approach might be to flatten the structure in pandas first\n",
        "        # For now, stick to the original py_function approach for demonstration\n",
        "        # Re-evaluate this if performance is an issue\n",
        "        return tf.py_function(\n",
        "            func=load_and_preprocess_for_tf,\n",
        "            # Need to pass Python objects to py_function, decode tensors first\n",
        "            inp=[img_path, bboxes_ragged_str], # This inp needs adjustment based on how ragged string is handled\n",
        "            Tout=[tf.float32, tf.float32, tf.int64] # img, boxes, classes\n",
        "        )\n",
        "\n",
        "    # Use tf.py_function to map the loading/preprocessing function\n",
        "    # Passing complex Python objects like list of dicts requires careful handling\n",
        "    dataset = dataset.map(lambda img_path, bboxes_list_tf: tf.py_function(\n",
        "            # The bboxes_list_tf needs to be converted back to a Python list of dicts here\n",
        "            # This is non-trivial within tf.py_function. Let's simplify.\n",
        "            # We will pass the raw list directly from pandas via the generator approach\n",
        "            func=load_and_preprocess_for_tf,\n",
        "            inp=[img_path, bboxes_list_tf], # Pass the tensor path and the list object\n",
        "            Tout=[tf.float32, tf.float32, tf.int64] # img, boxes, classes\n",
        "        ),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE # Parallelize mapping\n",
        "    )\n",
        "\n",
        "\n",
        "    # Set shapes after py_function (important!)\n",
        "    def set_shapes(img, boxes, classes):\n",
        "        img.set_shape([IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "        boxes.set_shape([None, 4]) # Variable number of boxes, 4 coords each\n",
        "        classes.set_shape([None]) # Variable number of boxes\n",
        "        return img, boxes, classes\n",
        "    dataset = dataset.map(set_shapes, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    # Combine into the dictionary format expected by KerasCV models\n",
        "    def format_for_keras_cv(img, boxes, classes):\n",
        "         return {\"images\": img, \"bounding_boxes\": {\"boxes\": boxes, \"classes\": classes}}\n",
        "    dataset = dataset.map(format_for_keras_cv, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# --- Create the Training Dataset ---\n",
        "# Simpler approach using from_generator which handles Python objects more easily\n",
        "def train_generator():\n",
        "    for _, row in train_data_pd.iterrows():\n",
        "        yield (row['image_path'], row['bboxes_parsed'])\n",
        "\n",
        "train_tf_dataset = tf.data.Dataset.from_generator(\n",
        "    train_generator,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.object) # Specify object for list of dicts\n",
        "    )\n",
        ")\n",
        "\n",
        "# Map using the py_function wrapper\n",
        "train_tf_dataset = train_tf_dataset.map(lambda img_path, bboxes_list: tf.py_function(\n",
        "        func=load_and_preprocess_for_tf,\n",
        "        inp=[img_path, bboxes_list],\n",
        "        Tout=[tf.float32, tf.float32, tf.int64]\n",
        "    ),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "\n",
        "# Set shapes and format for KerasCV (same as before)\n",
        "def set_shapes(img, boxes, classes):\n",
        "    img.set_shape([IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "    boxes.set_shape([None, 4])\n",
        "    classes.set_shape([None])\n",
        "    return img, boxes, classes\n",
        "train_tf_dataset = train_tf_dataset.map(set_shapes, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "def format_for_keras_cv(img, boxes, classes):\n",
        "     return {\"images\": img, \"bounding_boxes\": {\"boxes\": boxes, \"classes\": classes}}\n",
        "train_tf_dataset = train_tf_dataset.map(format_for_keras_cv, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "print(\"\\nCreating training tf.data.Dataset...\")\n",
        "# Apply shuffling, padding, batching, prefetching\n",
        "train_tf_dataset = train_tf_dataset.shuffle(BUFFER_SIZE)\n",
        "\n",
        "# Pad batches: Images are fixed size, bounding boxes need padding.\n",
        "# KerasCV handles ragged tensors internally often, but explicit padding is safer.\n",
        "# Pad bounding boxes to a max number, e.g., 100 per image. Use -1 for padding value.\n",
        "train_tf_dataset = train_tf_dataset.padded_batch(\n",
        "    BATCH_SIZE,\n",
        "    padding_values={\n",
        "        \"images\": tf.constant(0.0, dtype=tf.float32),\n",
        "        \"bounding_boxes\": {\n",
        "            \"boxes\": tf.constant(0.0, dtype=tf.float32), # Pad boxes with 0\n",
        "            \"classes\": tf.constant(-1, dtype=tf.int64)   # Pad classes with -1\n",
        "        }\n",
        "    },\n",
        "    padded_shapes={\n",
        "        \"images\": [IMG_HEIGHT, IMG_WIDTH, 3],\n",
        "        \"bounding_boxes\": {\n",
        "            \"boxes\": [None, 4],    # Pad first dimension (num_boxes) dynamically\n",
        "            \"classes\": [None]      # Pad first dimension (num_boxes) dynamically\n",
        "        }\n",
        "    },\n",
        "    drop_remainder=True # Important for consistent batch shapes during training\n",
        ")\n",
        "train_tf_dataset = train_tf_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"Training Dataset Element Spec (after formatting and batching):\")\n",
        "print(train_tf_dataset.element_spec)\n",
        "\n",
        "\n",
        "# --- Create the Validation Dataset ---\n",
        "if not val_data_pd.empty:\n",
        "    print(\"\\nCreating validation tf.data.Dataset...\")\n",
        "    def val_generator():\n",
        "        for _, row in val_data_pd.iterrows():\n",
        "            yield (row['image_path'], row['bboxes_parsed'])\n",
        "\n",
        "    val_tf_dataset = tf.data.Dataset.from_generator(\n",
        "        val_generator,\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "            tf.TensorSpec(shape=(None,), dtype=tf.object)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    val_tf_dataset = val_tf_dataset.map(lambda img_path, bboxes_list: tf.py_function(\n",
        "            func=load_and_preprocess_for_tf,\n",
        "            inp=[img_path, bboxes_list],\n",
        "            Tout=[tf.float32, tf.float32, tf.int64]\n",
        "        ),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "\n",
        "    val_tf_dataset = val_tf_dataset.map(set_shapes, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    val_tf_dataset = val_tf_dataset.map(format_for_keras_cv, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    # No shuffling for validation\n",
        "    val_tf_dataset = val_tf_dataset.padded_batch(\n",
        "        BATCH_SIZE,\n",
        "        padding_values={ # Match training padding values\n",
        "            \"images\": tf.constant(0.0, dtype=tf.float32),\n",
        "            \"bounding_boxes\": {\n",
        "                \"boxes\": tf.constant(0.0, dtype=tf.float32),\n",
        "                \"classes\": tf.constant(-1, dtype=tf.int64)\n",
        "            }\n",
        "        },\n",
        "        padded_shapes={ # Match training padding shapes\n",
        "            \"images\": [IMG_HEIGHT, IMG_WIDTH, 3],\n",
        "            \"bounding_boxes\": {\n",
        "                \"boxes\": [None, 4],\n",
        "                \"classes\": [None]\n",
        "            }\n",
        "        },\n",
        "        drop_remainder=True # Also drop remainder for validation if using metrics sensitive to batch size\n",
        "    )\n",
        "    val_tf_dataset = val_tf_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    print(\"Validation Dataset Element Spec (after formatting and batching):\")\n",
        "    print(val_tf_dataset.element_spec)\n",
        "else:\n",
        "    val_tf_dataset = None\n",
        "    print(\"\\nValidation dataset is empty or was not created.\")\n",
        "\n",
        "print(\"\\nTensorFlow dataset preparation finished.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5: Define the Object Detection Model (YOLOv8 from KerasCV)\n",
        "\n",
        "Instantiate a pre-trained YOLOv8 model from KerasCV and compile it with appropriate object detection loss and metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Define the Object Detection Model (YOLOv8 from KerasCV)\n",
        "\n",
        "print(\"Defining the YOLOv8 Object Detection Model...\")\n",
        "\n",
        "# --- Configuration for YOLOv8 ---\n",
        "# Choose a preset. Smaller presets train faster but might be less accurate.\n",
        "# Options include: \"yolo_v8_xs_pascalvoc\", \"yolo_v8_s_pascalvoc\", \"yolo_v8_m_pascalvoc\", etc.\n",
        "# Using \"_pascalvoc\" presets loads weights pre-trained on Pascal VOC dataset.\n",
        "# We use the 'detector' which includes the detection head.\n",
        "PRESET_NAME = \"yolo_v8_s_pascalvoc\" # Start with 'small' PascalVOC model\n",
        "# PRESET_NAME = \"yolo_v8_m_pascalvoc\" # Alternative: Medium model\n",
        "# PRESET_NAME = \"yolo_v8_s_coco\" # Alternative: Use COCO preset (more classes initially)\n",
        "\n",
        "# Define the bounding box format KerasCV expects\n",
        "# Already set TARGET_BBOX_FORMAT = \"xyxy\"\n",
        "\n",
        "# --- Instantiate the YOLOv8 Detector ---\n",
        "# This will download pre-trained weights the first time you run it.\n",
        "print(f\"Instantiating YOLOv8 Detector with preset: {PRESET_NAME}\")\n",
        "model = keras_cv.models.YOLOV8Detector.from_preset(\n",
        "    preset=PRESET_NAME,\n",
        "    bounding_box_format=TARGET_BBOX_FORMAT,\n",
        "    num_classes=NUM_CLASSES # Your number of classes (1 for 'debris')\n",
        ")\n",
        "\n",
        "# --- Compile the Model with Appropriate Loss and Metrics ---\n",
        "print(\"Compiling the model...\")\n",
        "# KerasCV provides standard object detection losses and metrics\n",
        "# The ObjectDetectionLoss combines classification (e.g., Focal) and box (e.g., CIoU) losses.\n",
        "optimizer = Adam(learning_rate=1e-4) # Adjust learning rate as needed (start low for fine-tuning)\n",
        "# optimizer = tf.keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-4) # AdamW often works well\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    # Use the built-in KerasCV loss for object detection\n",
        "    loss=keras_cv.losses.ObjectDetectionLoss(\n",
        "        classification_loss=keras_cv.losses.FocalLoss(from_logits=True, reduction=\"sum\"),\n",
        "        box_loss=keras_cv.losses.IoULoss(bounding_box_format=TARGET_BBOX_FORMAT, mode=\"ciou\", reduction=\"sum\")\n",
        "    ),\n",
        "    # Use standard COCO metrics for evaluation (calculated differently than simple accuracy)\n",
        "    metrics=[\n",
        "        keras_cv.metrics.BoxCOCOMetrics(\n",
        "            bounding_box_format=TARGET_BBOX_FORMAT,\n",
        "            evaluate_freq=1, # Evaluate every epoch\n",
        "            name=\"BoxCOCOMetrics\" # Explicit name for easier history access\n",
        "        )\n",
        "    ]\n",
        "    # Alternatively, you can use metrics=['accuracy'] during initial debugging,\n",
        "    # but it's not meaningful for object detection evaluation.\n",
        "    # metrics=['accuracy'] # Placeholder - DO NOT USE FOR FINAL EVALUATION\n",
        ")\n",
        "\n",
        "# Display model summary (can be very large for complex models)\n",
        "try:\n",
        "    model.summary(expand_nested=True) # Expand nested layers for more detail\n",
        "except ValueError as e:\n",
        "    print(f\"\\nNote: model.summary() might fail before model is built. Error: {e}\")\n",
        "    print(\"Model structure will be fully defined after the first batch of data.\")\n",
        "\n",
        "print(\"\\nYOLOv8 model defined and compiled.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 6: Train the Model\n",
        "\n",
        "Train the compiled YOLOv8 model using the prepared `tf.data` pipelines. Use callbacks to save the best model weights, stop early if performance plateaus, and reduce the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Train the Model\n",
        "\n",
        "print(\"Starting model training...\")\n",
        "\n",
        "# --- Configuration for Training ---\n",
        "NUM_EPOCHS = 25 # Increase epochs for better results, e.g., 25, 50, or more\n",
        "print(f\"Attempting to train for {NUM_EPOCHS} epochs.\")\n",
        "print(f\"Checkpoints will be saved in: {MODEL_SAVE_DIR}\")\n",
        "\n",
        "# --- Define Callbacks ---\n",
        "# 1. ModelCheckpoint: Save weights\n",
        "checkpoint_filename = \"yolov8_debris_epoch_{epoch:02d}-val_loss_{val_loss:.4f}.weights.h5\"\n",
        "checkpoint_path = os.path.join(MODEL_SAVE_DIR, checkpoint_filename)\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss', # Monitor validation loss\n",
        "    mode='min',\n",
        "    save_best_only=True, # Save only the best model based on monitored value\n",
        "    save_freq='epoch',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 2. EarlyStopping: Stop training if validation loss doesn't improve\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10, # Number of epochs with no improvement after which training will be stopped\n",
        "    verbose=1,\n",
        "    mode='min',\n",
        "    restore_best_weights=True # Restore weights from the epoch with the best monitor value\n",
        ")\n",
        "\n",
        "# 3. ReduceLROnPlateau: Reduce learning rate if validation loss plateaus\n",
        "reduce_lr_callback = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2, # Factor by which the learning rate will be reduced. new_lr = lr * factor\n",
        "    patience=5, # Number of epochs with no improvement after which learning rate will be reduced\n",
        "    verbose=1,\n",
        "    mode='min',\n",
        "    min_lr=1e-6 # Lower bound on the learning rate\n",
        ")\n",
        "\n",
        "# --- Check if validation data is available ---\n",
        "callbacks_list = [model_checkpoint_callback, early_stopping_callback, reduce_lr_callback]\n",
        "if val_tf_dataset is None:\n",
        "    print(\"WARNING: No validation dataset available. Training without validation callbacks (EarlyStopping, ReduceLR).\")\n",
        "    # Remove callbacks that rely on validation data\n",
        "    callbacks_list = [model_checkpoint_callback]\n",
        "    validation_args = {}\n",
        "else:\n",
        "    validation_args = {'validation_data': val_tf_dataset}\n",
        "\n",
        "# --- Calculate Steps (Optional but recommended for large datasets) ---\n",
        "# If using tf.data with .repeat(), specify steps_per_epoch\n",
        "# steps_per_epoch = len(train_data_pd) // BATCH_SIZE\n",
        "# validation_steps = len(val_data_pd) // BATCH_SIZE if val_tf_dataset is not None else None\n",
        "# print(f\"Calculated steps per epoch: {steps_per_epoch}\")\n",
        "# print(f\"Calculated validation steps: {validation_steps}\")\n",
        "\n",
        "# --- Start Training ---\n",
        "history = model.fit(\n",
        "    train_tf_dataset,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    callbacks=callbacks_list,\n",
        "    # steps_per_epoch=steps_per_epoch, # Uncomment if using steps\n",
        "    # validation_steps=validation_steps, # Uncomment if using steps\n",
        "    **validation_args # Pass validation_data only if available\n",
        ")\n",
        "\n",
        "print(\"\\nTraining finished.\")\n",
        "# If EarlyStopping restored best weights, the current model state reflects the best epoch.\n",
        "\n",
        "# --- Plot training history ---\n",
        "if val_tf_dataset is not None and 'val_loss' in history.history:\n",
        "    print(\"\\nPlotting training history...\")\n",
        "    try:\n",
        "        plt.style.use('seaborn-v0_8-darkgrid') # Use a nice style\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(16, 5)) # Create 2 subplots\n",
        "\n",
        "        # Plot Loss\n",
        "        axes[0].plot(history.history['loss'], label='Training Loss', marker='o', linestyle='--')\n",
        "        axes[0].plot(history.history['val_loss'], label='Validation Loss', marker='o', linestyle='-')\n",
        "        axes[0].set_title('Model Loss Over Epochs')\n",
        "        axes[0].set_xlabel('Epoch')\n",
        "        axes[0].set_ylabel('Loss Value')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True)\n",
        "\n",
        "        # Plot Metrics (Find the COCO metric name - might be 'BoxCOCOMetrics', 'MaP', etc.)\n",
        "        # Find the actual metric key from history.history.keys()\n",
        "        # Metric names might include loss components, filter them out\n",
        "        metric_keys = [k for k in history.history.keys() if 'loss' not in k and not k.startswith('val_') and k != 'lr']\n",
        "        val_metric_keys = [k for k in history.history.keys() if k.startswith('val_') and 'loss' not in k]\n",
        "\n",
        "        if metric_keys and val_metric_keys:\n",
        "            # Plot the first available primary metric (likely COCO metric)\n",
        "            metric_name = metric_keys[0] # e.g., 'BoxCOCOMetrics'\n",
        "            val_metric_name = val_metric_keys[0] # e.g., 'val_BoxCOCOMetrics'\n",
        "\n",
        "            # The history object stores the *result* of the metric computation, which for BoxCOCOMetrics is a dict\n",
        "            # We need to extract a specific value, e.g., 'MaP'\n",
        "            if isinstance(history.history[metric_name][0], dict):\n",
        "                 # Extract MaP if available\n",
        "                 train_map = [epoch_metrics.get('MaP', np.nan) for epoch_metrics in history.history[metric_name]]\n",
        "                 val_map = [epoch_metrics.get('MaP', np.nan) for epoch_metrics in history.history[val_metric_name]]\n",
        "                 metric_label = 'MaP'\n",
        "            else:\n",
        "                 # Fallback if the metric isn't a dict (shouldn't happen with BoxCOCOMetrics)\n",
        "                 train_map = history.history[metric_name]\n",
        "                 val_map = history.history[val_metric_name]\n",
        "                 metric_label = metric_name\n",
        "\n",
        "            axes[1].plot(train_map, label=f'Training {metric_label}', marker='s', linestyle='--')\n",
        "            axes[1].plot(val_map, label=f'Validation {metric_label}', marker='s', linestyle='-')\n",
        "            axes[1].set_title(f'Model Metric ({metric_label}) Over Epochs')\n",
        "            axes[1].set_xlabel('Epoch')\n",
        "            axes[1].set_ylabel('Metric Value (e.g., mAP)')\n",
        "            axes[1].legend()\n",
        "            axes[1].grid(True)\n",
        "        else:\n",
        "             axes[1].set_title('Metrics Plot Unavailable')\n",
        "             axes[1].text(0.5, 0.5, 'No suitable metrics found in history', horizontalalignment='center', verticalalignment='center')\n",
        "\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Save the plot\n",
        "        plot_save_path = os.path.join(MODEL_SAVE_DIR, \"training_history_plot.png\")\n",
        "        fig.savefig(plot_save_path)\n",
        "        print(f\"Training history plot saved to: {plot_save_path}\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"Matplotlib not found. Skipping history plot.\")\n",
        "    except Exception as plot_e:\n",
        "        print(f\"Error plotting history: {plot_e}\")\n",
        "else:\n",
        "    print(\"\\nSkipping training history plot (no validation data or metrics).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 7: Evaluate the Model\n",
        "\n",
        "Load the best weights (restored by EarlyStopping or loaded manually) and evaluate the model's performance on the validation set using the compiled COCO metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Evaluate the Model\n",
        "\n",
        "print(\"Evaluating the trained model...\")\n",
        "\n",
        "# --- Load the Best Saved Weights ---\n",
        "# If EarlyStopping was used with restore_best_weights=True, the 'model' object already has the best weights.\n",
        "# Otherwise, find and load the best checkpoint saved by ModelCheckpoint.\n",
        "best_checkpoint_path = None\n",
        "try:\n",
        "    # Find the checkpoint file saved by save_best_only=True (based on val_loss)\n",
        "    # This requires parsing filenames, which can be brittle. A more robust way is to save the best explicitly.\n",
        "    # For now, let's assume EarlyStopping worked or we load the latest best.\n",
        "    # If EarlyStopping didn't run or restore_best_weights=False, find the best manually:\n",
        "    checkpoints = [os.path.join(MODEL_SAVE_DIR, f) for f in os.listdir(MODEL_SAVE_DIR) if f.endswith('.weights.h5')]\n",
        "    if checkpoints:\n",
        "        checkpoints.sort(key=os.path.getmtime) # Sort by modification time\n",
        "        # If save_best_only=True, the latest might not be the best if training continued past the best epoch.\n",
        "        # A better approach: Parse val_loss from filenames to find the minimum.\n",
        "        best_val_loss = float('inf')\n",
        "        for chkpt in checkpoints:\n",
        "            try:\n",
        "                # Extract val_loss, be robust to filename format variations\n",
        "                val_loss_str = chkpt.split('val_loss_')[-1].split('.weights.h5')[0]\n",
        "                current_val_loss = float(val_loss_str)\n",
        "                if current_val_loss < best_val_loss:\n",
        "                    best_val_loss = current_val_loss\n",
        "                    best_checkpoint_path = chkpt\n",
        "            except (IndexError, ValueError):\n",
        "                print(f\"Warning: Could not parse val_loss from checkpoint filename: {chkpt}\")\n",
        "                continue # Skip file if parsing fails\n",
        "\n",
        "        if best_checkpoint_path:\n",
        "             print(f\"Identified best checkpoint (lowest val_loss): {best_checkpoint_path}\")\n",
        "        else:\n",
        "             print(\"Warning: Could not determine the best checkpoint from filenames. Using model state from end of training.\")\n",
        "    else:\n",
        "        print(\"No checkpoints found in directory. Using model state from end of training.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error finding checkpoints: {e}. Using model state from end of training.\")\n",
        "\n",
        "# Decide whether to load weights or use the current model state\n",
        "if best_checkpoint_path and os.path.exists(best_checkpoint_path):\n",
        "    print(f\"Loading weights from best checkpoint: {best_checkpoint_path}\")\n",
        "    # Re-create the model architecture (important if not using the 'model' object directly)\n",
        "    eval_model = keras_cv.models.YOLOV8Detector.from_preset(\n",
        "        preset=PRESET_NAME,\n",
        "        bounding_box_format=TARGET_BBOX_FORMAT,\n",
        "        num_classes=NUM_CLASSES\n",
        "    )\n",
        "    eval_model.load_weights(best_checkpoint_path)\n",
        "    # Re-compile is essential after loading weights\n",
        "    print(\"Compiling loaded model...\")\n",
        "    eval_model.compile(\n",
        "        optimizer=optimizer, # Use the same optimizer config\n",
        "        loss=keras_cv.losses.ObjectDetectionLoss(\n",
        "            classification_loss=keras_cv.losses.FocalLoss(from_logits=True, reduction=\"sum\"),\n",
        "            box_loss=keras_cv.losses.IoULoss(bounding_box_format=TARGET_BBOX_FORMAT, mode=\"ciou\", reduction=\"sum\")\n",
        "        ),\n",
        "        metrics=[keras_cv.metrics.BoxCOCOMetrics(bounding_box_format=TARGET_BBOX_FORMAT, name=\"BoxCOCOMetrics\")]\n",
        "    )\n",
        "    print(\"Model loaded with best weights and compiled.\")\n",
        "else:\n",
        "    print(\"Using model state directly from training (assuming EarlyStopping restored best weights or no better checkpoint found).\")\n",
        "    eval_model = model # Use the model object directly from training\n",
        "\n",
        "\n",
        "# --- Evaluate on Validation Set ---\n",
        "if eval_model and val_tf_dataset:\n",
        "    print(\"\\nEvaluating on Validation Set using compiled COCO metrics...\")\n",
        "    results = eval_model.evaluate(val_tf_dataset, verbose=1)\n",
        "    print(\"\\nValidation Results:\")\n",
        "    if isinstance(results, list): # evaluate returns list: [loss, metric1_value, metric2_value,...]\n",
        "        print(f\"  Validation Loss    : {results[0]:.4f}\")\n",
        "        # Print metrics based on the names compiled into the model\n",
        "        for i, metric_name in enumerate(eval_model.metrics_names[1:]): # Skip 'loss'\n",
        "             metric_value = results[i+1]\n",
        "             # COCO Metrics often return a dictionary of values (mAP, mAP50, etc.)\n",
        "             if isinstance(metric_value, dict):\n",
        "                 print(f\"  Validation {metric_name}:\")\n",
        "                 for sub_metric, value in metric_value.items():\n",
        "                     print(f\"    - {sub_metric}: {value:.4f}\")\n",
        "             else:\n",
        "                 print(f\"  Validation {metric_name}: {metric_value:.4f}\")\n",
        "    else: # Single loss value if no metrics compiled (shouldn't happen here)\n",
        "        print(f\"  Validation Loss    : {results:.4f}\")\n",
        "\n",
        "elif not eval_model:\n",
        "    print(\"\\nSkipping validation evaluation (model not available).\")\n",
        "else:\n",
        "    print(\"\\nSkipping validation evaluation (validation data not available).\")\n",
        "\n",
        "\n",
        "# --- Conceptual: Prediction on Test Set ---\n",
        "# 1. Prepare Test Dataset (Images Only)\n",
        "print(\"\\nConceptual: Preparing Test Dataset...\")\n",
        "try:\n",
        "    test_img_folder_name = os.path.basename(LOCAL_TEST_IMG_DIR) # e.g., 'test'\n",
        "    test_image_files_pattern = f\"{HDFS_TEST_IMG_DIR}/{test_img_folder_name}/*.jpg\" # Adjust pattern if needed\n",
        "    test_image_paths = tf.data.Dataset.list_files(test_image_files_pattern, shuffle=False)\n",
        "    print(f\"Found test image pattern: {test_image_files_pattern}\")\n",
        "\n",
        "    # Check if any files match the pattern\n",
        "    test_file_count = tf.data.experimental.cardinality(test_image_paths).numpy()\n",
        "    if test_file_count == 0:\n",
        "         print(\"Warning: No test files found matching the pattern.\")\n",
        "         raise FileNotFoundError # Raise error to skip prediction\n",
        "    else:\n",
        "         print(f\"Found {test_file_count} potential test files.\")\n",
        "\n",
        "\n",
        "    def load_and_preprocess_test_image(image_path_tensor):\n",
        "        try:\n",
        "            img_bytes = tf.io.read_file(image_path_tensor)\n",
        "            img = tf.image.decode_jpeg(img_bytes, channels=3)\n",
        "            img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH], method='bilinear')\n",
        "            img = tf.cast(img, dtype=tf.float32)\n",
        "            # KerasCV predict expects dictionary format\n",
        "            return {\"images\": img}\n",
        "        except Exception as e:\n",
        "            tf.print(f\"Error loading test image {image_path_tensor}: {e}\")\n",
        "            return {\"images\": tf.zeros([IMG_HEIGHT, IMG_WIDTH, 3], dtype=tf.float32)} # Return dummy\n",
        "\n",
        "    test_tf_dataset = test_image_paths.map(load_and_preprocess_test_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    # Batch the test dataset\n",
        "    test_tf_dataset = test_tf_dataset.batch(BATCH_SIZE) # Use a batch size suitable for inference\n",
        "    test_tf_dataset = test_tf_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    print(\"Test dataset prepared conceptually.\")\n",
        "\n",
        "    # 2. Run Prediction\n",
        "    if eval_model:\n",
        "        print(\"\\nRunning predictions on Test Set...\")\n",
        "        # Use model.predict() for inference\n",
        "        # KerasCV detectors return bounding boxes in a dictionary format\n",
        "        predictions = eval_model.predict(test_tf_dataset, verbose=1)\n",
        "\n",
        "        # 'predictions' structure depends on the model, for KerasCV YOLOv8:\n",
        "        # It's often a dictionary like {'boxes': ..., 'classes': ..., 'confidence': ...}\n",
        "        # The shapes would be [batch, num_detections, 4] for boxes, [batch, num_detections] for classes/confidence\n",
        "        print(\"\\nSample Prediction Output Structure (first batch):\")\n",
        "        if isinstance(predictions, dict):\n",
        "            for key, value in predictions.items():\n",
        "                 # Check if value is a tensor/numpy array before accessing shape\n",
        "                 if hasattr(value, 'shape'):\n",
        "                     print(f\"  Key: '{key}', Shape: {value.shape}, Dtype: {value.dtype}\")\n",
        "                 else:\n",
        "                     print(f\"  Key: '{key}', Value Type: {type(value)}\")\n",
        "        else:\n",
        "             print(f\"  Prediction Type: {type(predictions)}\")\n",
        "             if hasattr(predictions, 'shape'):\n",
        "                 print(f\"  Prediction Shape: {predictions.shape}\")\n",
        "\n",
        "\n",
        "        # 3. Post-process Predictions (Example)\n",
        "        # - Filter boxes based on confidence threshold\n",
        "        # - Apply Non-Max Suppression (NMS) if not done by the model\n",
        "        # - Convert relative coordinates back to absolute pixel values if needed\n",
        "        # - Visualize results (draw boxes on images)\n",
        "\n",
        "        print(\"\\nPrediction finished. Further post-processing needed to use/visualize results.\")\n",
        "        # Add visualization code here if desired, iterating through predictions and images.\n",
        "\n",
        "    else:\n",
        "        print(\"\\nSkipping test set prediction (model not available).\")\n",
        "\n",
        "except (tf.errors.NotFoundError, FileNotFoundError):\n",
        "     print(f\"\\nError: Test image files not found at pattern: {test_image_files_pattern}\")\n",
        "     print(\"Skipping test set prediction.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred during test set preparation or prediction: {e}\")\n",
        "    print(\"Skipping test set prediction.\")\n",
        "\n",
        "\n",
        "print(\"\\nEvaluation and Prediction conceptual steps finished.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 8: Stop SparkSession\n",
        "\n",
        "Release the resources used by the SparkSession."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Stop SparkSession\n",
        "print(\"\\nStopping SparkSession...\")\n",
        "try:\n",
        "    spark.stop()\n",
        "    print(\"SparkSession stopped successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error stopping SparkSession: {e}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf_new_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
